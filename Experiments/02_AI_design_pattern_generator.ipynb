{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c153d113",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chat_models import init_chat_model\n",
    "from langchain.prompts import PromptTemplate\n",
    "import json,os\n",
    "import threading\n",
    "\n",
    "llm = init_chat_model(\"gemini-2.5-flash\",model_provider=\"google_genai\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "09155d9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "msg = \"\"\"\n",
    "Generate {count} Python programs that implement the {pattern} Design Pattern. Design pattern is described bottom.\n",
    "\n",
    "Output must follow these rules:\n",
    "Add realword usages of the pattern.\n",
    "Add also some simulation pattern\n",
    "The result must be a **JSON Array of exactly {count} strings**.\n",
    "Each string must contain a **complete, standalone Python program**.\n",
    "No explanations, no comments, no markdown formatting, no citations, no extra text.\n",
    "Don't include any text outside the JSON array. Like `````json` or ```python`.\n",
    "Each program must be different from the others. Make sure patterns are represents different systems like banking, healthcare, education, e-commerce, etc.\n",
    "\n",
    "About Design Pattern:\n",
    "Problem:\n",
    "{problem}\n",
    "Context:\n",
    "{context}\n",
    "Solution:\n",
    "{solution}\n",
    "\"\"\"\n",
    "msg = PromptTemplate(\n",
    "    template=msg,\n",
    "    input_variables=[\"pattern\",\"count\",\"problem\",\"context\",\"solution\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "1533d12f",
   "metadata": {},
   "outputs": [],
   "source": [
    "chain = msg | llm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33d4847e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import ast, re\n",
    "\n",
    "def extract_first_list(s):\n",
    "    match = re.search(r'\\[.*?\\]', s)\n",
    "    if match:\n",
    "        return ast.literal_eval(match.group(0))\n",
    "    return []\n",
    "\n",
    "def generate_code(pattern: dict, count: int):\n",
    "    print(f\"Generating {count} code examples for the {pattern['Pattern Name']} pattern...\")\n",
    "    return chain.invoke({\"pattern\": pattern['Pattern Name'], \"count\": count, \"problem\": pattern['Problem'], \"context\": pattern['Context'], \"solution\": pattern['Solution']})\n",
    "\n",
    "def save_code(output, pattern: dict, base_path: str, starting_index=1):\n",
    "    try:\n",
    "        output.content = extract_first_list(output.content)\n",
    "        json_output = json.loads(output.content)\n",
    "    except json.JSONDecodeError as e:\n",
    "        print(f\"Error decoding JSON for pattern {pattern['Pattern Name']}: {e}\")\n",
    "        print(f\"Output content: {output.content}\")\n",
    "        return\n",
    "    for i, code in enumerate(json_output):\n",
    "        os.makedirs(f\"{base_path}/{pattern['Pattern Name']}\", exist_ok=True)\n",
    "        with open(f\"{base_path}/{pattern['Pattern Name']}/{pattern['Pattern Name']}_pattern_{starting_index+i}.py\", \"w\") as file:\n",
    "            file.write(code)\n",
    "    \n",
    "    print(f\"Saved {pattern['Pattern Name']} pattern examples\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "9459e1c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def ai_design_patterns(patterns, base_path, pattern_count=10,starting_index=1):\n",
    "    for pattern in patterns:\n",
    "        output = generate_code(pattern, pattern_count)\n",
    "        save_code(output, pattern, base_path,starting_index)\n",
    "\n",
    "def ai_design_patterns_threaded(patterns,base_path,pattern_count=10,starting_index=1):\n",
    "    threads = []\n",
    "    for pattern in patterns:\n",
    "        t = threading.Thread(target=lambda p=pattern: save_code(generate_code(p,pattern_count),p,base_path,starting_index))\n",
    "        threads.append(t)\n",
    "        t.start()\n",
    "    for t in threads:\n",
    "        t.join()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "50715e01",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating 3 code examples for the Parallel Tool Execution pattern...\n",
      "Generating 3 code examples for the Adversarial Agent Interaction pattern...\n",
      "Generating 3 code examples for the Comprehensive Black-Box Explainability and Analysis Framework pattern...\n",
      "Saved Adversarial Agent Interaction pattern examples\n",
      "Saved Parallel Tool Execution pattern examples\n",
      "Error decoding JSON for pattern Holistic LLM Agentic Framework: Expecting value: line 5 column 1 (char 37065)\n",
      "Output content: [\n",
      "\"import random\\nimport time\\n\\nclass HealthcareAgent:\\n    def __init__(self):\\n        self.working_memory = {}\\n        self.episodic_memory = [] # Store past patient interactions/diagnoses\\n        self.semantic_memory = {\\n            \\\"fever\\\": \\\"Elevated body temperature, often a symptom of infection or inflammation.\\\",\\n            \\\"cough\\\": \\\"A reflex action to clear the airways of mucus or irritants.\\\",\\n            \\\"headache\\\": \\\"Pain in the head or face.\\\",\\n            \\\"diabetes_type2\\\": \\\"A chronic condition that affects the way the body processes blood sugar (glucose).\\\",\\n            \\\"hypertension\\\": \\\"High blood pressure, a common condition in which the long-term force of the blood against your artery walls is high enough that it may eventually cause health problems, such as heart disease.\\\",\\n            \\\"insulin\\\": \\\"A hormone produced in the pancreas that regulates the amount of glucose in the blood.\\\",\\n            \\\"metformin\\\": \\\"An oral medication that helps control blood sugar levels.\\\",\\n            \\\"paracetamol\\\": \\\"A common pain reliever and fever reducer.\\\",\\n            \\\"antibiotics\\\": \\\"Medications that fight bacterial infections.\\\",\\n            \\\"diet_plan_diabetes\\\": \\\"Low sugar, balanced carbs, high fiber.\\\",\\n            \\\"exercise_plan_hypertension\\\": \\\"Regular aerobic exercise, 30 mins a day.\\\"\\n        }\\n        self.procedural_memory = {\\n            \\\"interpret_labs\\\": self._tool_lab_interpreter,\\n            \\\"check_drug_interaction\\\": self._tool_drug_interaction_checker,\\n            \\\"retrieve_guidelines\\\": self._retrieve_guidelines\\n        }\\n        self.patient_profiles = {\\n            \\\"John Doe\\\": {\\\"age\\\": 55, \\\"conditions\\\": [\\\"diabetes_type2\\\", \\\"hypertension\\\"], \\\"allergies\\\": [], \\\"medications\\\": [\\\"metformin\\\"], \\\"preferences\\\": {\\\"diet\\\": \\\"low-carb\\\"}}\\n        }\\n\\n    def _llm_inference(self, prompt, context=None):\\n        # Simulates LLM's core reasoning, intent understanding, and direct generation\\n        # In a real system, this would be an API call to an actual LLM.\\n        print(f\\\"  [LLM] Processing prompt: '{prompt}' with context: {context}\\\")\\n        if \\\"clarify\\\" in prompt.lower() or \\\"understand\\\" in prompt.lower():\\n            return \\\"Please provide more details about the patient's main concern or specific symptoms.\\\"\\n        elif \\\"diagnosis\\\" in prompt.lower() and \\\"symptoms\\\" in str(context).lower():\\n            symptoms = context.get(\\\"symptoms\\\", \\\"\\\")\\n            if \\\"fever\\\" in symptoms and \\\"cough\\\" in symptoms:\\n                return \\\"Based on the symptoms, a common cold or flu is likely. Further tests may be needed.\\\"\\n            elif \\\"high glucose\\\" in symptoms and \\\"fatigue\\\" in symptoms:\\n                return \\\"Considering the symptoms and patient history, a diabetes management review is recommended.\\\"\\n            else:\\n                return \\\"Further information is needed for a precise diagnosis.\\\"\\n        elif \\\"treatment plan\\\" in prompt.lower() and \\\"diagnosis\\\" in str(context).lower():\\n            diagnosis = context.get(\\\"diagnosis\\\")\\n            patient_name = context.get(\\\"patient_name\\\")\\n            patient_profile = self.patient_profiles.get(patient_name, {})\\n\\n            plan = f\\\"For {patient_name} with {diagnosis}:\\\\n\\\"\\n            if \\\"diabetes_type2\\\" in diagnosis:\\n                plan += \\\"  - Medication review (e.g., Metformin adjustment if needed).\\\\n\\\"\\n                plan += \\\"  - Implement a personalized diet plan: {}.\\\\n\\\".format(patient_profile.get(\\\"preferences\\\", {}).get(\\\"diet\\\", \\\"standard diabetes diet\\\"))\\n                plan += \\\"  - Regular blood sugar monitoring.\\\\n\\\"\\n            if \\\"hypertension\\\" in diagnosis:\\n                plan += \\\"  - Lifestyle modifications: {}.\\\\n\\\".format(self.semantic_memory.get(\\\"exercise_plan_hypertension\\\"))\\n                plan += \\\"  - Blood pressure monitoring.\\\\n\\\"\\n            plan += \\\"  - Follow-up in 2 weeks.\\\\n\\\"\\n            return plan\\n        elif \\\"recommend\\\" in prompt.lower() and \\\"diet\\\" in prompt.lower():\\n            return self.semantic_memory.get(\\\"diet_plan_diabetes\\\", \\\"General healthy eating guidelines.\\\")\\n        return \\\"I am processing your request.\\\"\\n\\n    def _retrieve_guidelines(self, query):\\n        # Simulates RAG: Retrieves relevant info from semantic memory\\n        print(f\\\"  [RAG] Retrieving guidelines for: {query}\\\")\\n        results = [v for k, v in self.semantic_memory.items() if query.lower() in k.lower() or query.lower() in v.lower()]\\n        return results[0] if results else \\\"No specific guidelines found.\\\"\\n\\n    def _tool_lab_interpreter(self, lab_results):\\n        # Simulates a tool for interpreting lab results\\n        print(f\\\"  [Tool] Interpreting lab results: {lab_results}\\\")\\n        interpretations = []\\n        if \\\"glucose\\\" in lab_results and lab_results[\\\"glucose\\\"] > 180:\\n            interpretations.append(\\\"High glucose level detected.\\\")\\n        if \\\"bp_systolic\\\" in lab_results and lab_results[\\\"bp_systolic\\\"] > 140:\\n            interpretations.append(\\\"Elevated systolic blood pressure.\\\")\\n        return \\\" \\\".join(interpretations) if interpretations else \\\"Lab results within normal limits.\\\"\\n\\n    def _tool_drug_interaction_checker(self, drugs, patient_conditions):\\n        # Simulates a tool for checking drug interactions and contraindications\\n        print(f\\\"  [Tool] Checking drug interactions for {drugs} with conditions {patient_conditions}\\\")\\n        if \\\"metformin\\\" in drugs and \\\"kidney_failure\\\" in patient_conditions:\\n            return \\\"Warning: Metformin contraindicated in severe kidney failure.\\\"\\n        return \\\"No significant interactions or contraindications found.\\\"\\n\\n    def _verify_drug_plan(self, proposed_meds, patient_conditions):\\n        # Simulates factual verification and grounding actions\\n        print(f\\\"  [Verification] Verifying proposed medications: {proposed_meds}\\\")\\n        feedback = self.procedural_memory[\\\"check_drug_interaction\\\"](proposed_meds, patient_conditions)\\n        if \\\"Warning\\\" in feedback:\\n            return False, feedback\\n        return True, \\\"Medication plan verified.\\\"\\n\\n    def _plan_treatment(self, patient_name, symptoms, lab_results):\\n        # Simulates adaptive planning and decision-making\\n        print(f\\\"[Planning] Starting treatment plan for {patient_name} with symptoms: {symptoms}\\\")\\n        self.working_memory = {\\\"patient_name\\\": patient_name, \\\"symptoms\\\": symptoms, \\\"lab_results\\\": lab_results}\\n\\n        # Step 1: Interpret lab results (Tool Integration)\\n        lab_interpretation = self.procedural_memory[\\\"interpret_labs\\\"](lab_results)\\n        self.working_memory[\\\"lab_interpretation\\\"] = lab_interpretation\\n        print(f\\\"  Lab interpretation: {lab_interpretation}\\\")\\n\\n        # Step 2: LLM for initial diagnosis (Core Reasoning)\\n        diagnosis_prompt = f\\\"Based on symptoms: {symptoms} and lab interpretation: {lab_interpretation}, what is a likely diagnosis for {patient_name}?\\\"\\n        diagnosis = self._llm_inference(diagnosis_prompt, self.working_memory)\\n        self.working_memory[\\\"diagnosis\\\"] = diagnosis\\n        print(f\\\"  LLM Diagnosis: {diagnosis}\\\")\\n\\n        # Step 3: LLM generates treatment plan (Direct Generation, Hierarchical Planning)\\n        treatment_plan_prompt = f\\\"Generate a detailed treatment plan for {patient_name} with diagnosis: {diagnosis}.\\\"\\n        treatment_plan = self._llm_inference(treatment_plan_prompt, self.working_memory)\\n        self.working_memory[\\\"treatment_plan\\\"] = treatment_plan\\n        print(f\\\"  Initial Treatment Plan:\\\\n{treatment_plan}\\\")\\n\\n        # Step 4: Verify proposed medications (Verification, Grounding)\\n        patient_profile = self.patient_profiles.get(patient_name, {})\\n        proposed_meds = patient_profile.get(\\\"medications\\\", []) # Simplified: assumes plan includes existing meds\\n        if \\\"diabetes_type2\\\" in diagnosis: proposed_meds.append(\\\"metformin\\\")\\n        is_valid, verification_feedback = self._verify_drug_plan(proposed_meds, patient_profile.get(\\\"conditions\\\", []))\\n\\n        if not is_valid:\\n            print(f\\\"  [Self-Correction] Plan needs adjustment: {verification_feedback}\\\")\\n            # LLM would re-plan here. For simulation, we'll just acknowledge.\\n            self.working_memory[\\\"treatment_plan\\\"] += f\\\"\\\\n  [Correction Required]: {verification_feedback} - Review medications.\\\\n\\\"\\n        \\n        # Step 5: Store in episodic memory (Continuous Learning, Experience-Based Learning)\\n        self.episodic_memory.append({\\\"patient\\\": patient_name, \\\"timestamp\\\": time.time(), \\\"diagnosis\\\": diagnosis, \\\"plan\\\": self.working_memory[\\\"treatment_plan\\\"]})\\n        print(\\\"  Plan finalized and stored in episodic memory.\\\")\\n\\n        return self.working_memory[\\\"treatment_plan\\\"]\\n\\n    def _learn_from_feedback(self, patient_name, feedback):\\n        # Simulates finetuning/alignment based on human feedback\\n        print(f\\\"[Learning] Incorporating feedback for {patient_name}: '{feedback}'\\\")\\n        if \\\"prefers natural remedies\\\" in feedback.lower():\\n            if patient_name in self.patient_profiles:\\n                self.patient_profiles[patient_name][\\\"preferences\\\"][\\\"treatment_approach\\\"] = \\\"natural remedies\\\"\\n            print(f\\\"  Updated {patient_name}'s preferences to include natural remedies.\\\")\\n\\n    def run_simulation(self):\\n        print(\\\"--- Healthcare Agent Simulation Started ---\\\")\\n        patient_name = \\\"John Doe\\\"\\n        symptoms = \\\"fatigue, frequent urination, occasional blurred vision\\\"\\n        lab_results = {\\\"glucose\\\": 220, \\\"bp_systolic\\\": 150, \\\"bp_diastolic\\\": 90, \\\"hba1c\\\": 8.5}\\n\\n        # Scenario 1: Initial consultation and plan generation\\n        print(f\\\"\\\\n[Scenario 1] Patient: {patient_name}, Symptoms: {symptoms}, Lab Results: {lab_results}\\\")\\n        treatment_plan = self._plan_treatment(patient_name, symptoms, lab_results)\\n        print(f\\\"\\\\nFinal Proposed Treatment Plan for {patient_name}:\\\\n{treatment_plan}\\\")\\n\\n        # Scenario 2: Patient feedback and learning\\n        print(f\\\"\\\\n[Scenario 2] Patient {patient_name} provides feedback.\\\")\\n        self._learn_from_feedback(patient_name, \\\"I prefer a low-carb diet recommendation.\\\")\\n        print(f\\\"Updated patient profile for {patient_name}: {self.patient_profiles.get(patient_name)}\\\")\\n\\n        # Scenario 3: Clarifying intent\\n        print(\\\"\\\\n[Scenario 3] User asks a vague question.\\\")\\n        llm_response = self._llm_inference(\\\"I need help with my health.\\\")\\n        print(f\\\"Agent's response to vague query: {llm_response}\\\")\\n\\n        print(\\\"\\\\n--- Healthcare Agent Simulation Finished ---\\\")\\n\\nif __name__ == \\\"__main__\\\":\\n    agent = HealthcareAgent()\\n    agent.run_simulation()\",\n",
      "\"import random\\nimport time\\n\\nclass ECommerceAgent:\\n    def __init__(self):\\n        self.working_memory = {}\\n        self.episodic_memory = {} # User purchase history, browsing sessions\\n        self.semantic_memory = { # Product Catalog\\n            \\\"P001\\\": {\\\"name\\\": \\\"Laptop Pro\\\", \\\"category\\\": \\\"Electronics\\\", \\\"price\\\": 1200, \\\"stock\\\": 5, \\\"features\\\": \\\"16GB RAM, 512GB SSD\\\", \\\"reviews\\\": [\\\"Fast\\\", \\\"Great display\\\"]},\\n            \\\"P002\\\": {\\\"name\\\": \\\"Wireless Mouse\\\", \\\"category\\\": \\\"Electronics\\\", \\\"price\\\": 25, \\\"stock\\\": 50, \\\"features\\\": \\\"Ergonomic, Bluetooth\\\", \\\"reviews\\\": [\\\"Comfortable\\\", \\\"Good value\\\"]},\\n            \\\"P003\\\": {\\\"name\\\": \\\"Designer T-Shirt\\\", \\\"category\\\": \\\"Apparel\\\", \\\"price\\\": 45, \\\"stock\\\": 20, \\\"features\\\": \\\"Cotton, Slim Fit\\\", \\\"reviews\\\": [\\\"Stylish\\\", \\\"Soft material\\\"]},\\n            \\\"P004\\\": {\\\"name\\\": \\\"Coffee Maker\\\", \\\"category\\\": \\\"Home Goods\\\", \\\"price\\\": 80, \\\"stock\\\": 10, \\\"features\\\": \\\"Programmable, 12-cup\\\", \\\"reviews\\\": [\\\"Easy to use\\\", \\\"Makes great coffee\\\"]},\\n            \\\"P005\\\": {\\\"name\\\": \\\"Gaming Headset\\\", \\\"category\\\": \\\"Electronics\\\", \\\"price\\\": 99, \\\"stock\\\": 15, \\\"features\\\": \\\"Surround Sound, Mic\\\", \\\"reviews\\\": [\\\"Immersive audio\\\", \\\"Comfortable for long sessions\\\"]},\\n        }\\n        self.user_profiles = {\\n            \\\"user123\\\": {\\\"past_purchases\\\": [\\\"P001\\\", \\\"P002\\\"], \\\"preferences\\\": {\\\"category\\\": \\\"Electronics\\\", \\\"budget\\\": 1500}},\\n            \\\"user456\\\": {\\\"past_purchases\\\": [\\\"P003\\\"], \\\"preferences\\\": {\\\"category\\\": \\\"Apparel\\\", \\\"style\\\": \\\"casual\\\"}}\\n        }\\n        self.procedural_memory = {\\n            \\\"check_inventory\\\": self._tool_inventory_checker,\\n            \\\"compare_prices\\\": self._tool_price_comparator,\\n            \\\"retrieve_reviews\\\": self._retrieve_product_details # RAG-like for reviews\\n        }\\n\\n    def _llm_inference(self, prompt, context=None):\\n        # Simulates LLM's core reasoning, intent understanding, and direct generation\\n        print(f\\\"  [LLM] Processing prompt: '{prompt}' with context: {context}\\\")\\n        if \\\"recommend\\\" in prompt.lower() and \\\"electronics\\\" in prompt.lower():\\n            return \\\"Based on your interest in electronics, I recommend the Laptop Pro (P001) or Gaming Headset (P005).\\\"\\n        elif \\\"recommend\\\" in prompt.lower() and \\\"clothing\\\" in prompt.lower():\\n            return \\\"For clothing, the Designer T-Shirt (P003) is a popular choice.\\\"\\n        elif \\\"clarify\\\" in prompt.lower() or \\\"understand\\\" in prompt.lower():\\n            return \\\"Could you please specify what type of products you are looking for or your budget?\\\"\\n        elif \\\"explain\\\" in prompt.lower() and \\\"P001\\\" in prompt:\\n            product_info = self.semantic_memory.get(\\\"P001\\\", {}) \\n            return f\\\"The Laptop Pro (P001) is a high-performance electronic device with {product_info.get('features')}. It costs ${product_info.get('price')}.\\\"\\n        return \\\"I am processing your request.\\\"\\n\\n    def _retrieve_product_details(self, product_id):\\n        # Simulates RAG: Retrieves product details and reviews\\n        print(f\\\"  [RAG] Retrieving details for product: {product_id}\\\")\\n        product = self.semantic_memory.get(product_id)\\n        if product:\\n            return {\\\"name\\\": product[\\\"name\\\"], \\\"price\\\": product[\\\"price\\\"], \\\"reviews\\\": product[\\\"reviews\\\"]}\\n        return \\\"Product not found.\\\"\\n\\n    def _tool_inventory_checker(self, product_id):\\n        # Simulates a tool for checking product stock\\n        print(f\\\"  [Tool] Checking inventory for {product_id}\\\")\\n        product = self.semantic_memory.get(product_id)\\n        return product[\\\"stock\\\"] if product else 0\\n\\n    def _tool_price_comparator(self, product_id):\\n        # Simulates a tool for comparing prices (e.g., across vendors)\\n        print(f\\\"  [Tool] Comparing prices for {product_id}\\\")\\n        product = self.semantic_memory.get(product_id)\\n        if product:\\n            # Simulate a slight price variation\\n            return product[\\\"price\\\"] * random.uniform(0.95, 1.05)\\n        return None\\n\\n    def _verify_recommendation(self, product_id):\\n        # Simulates factual verification and grounding actions\\n        print(f\\\"  [Verification] Verifying recommendation for {product_id}\\\")\\n        stock = self.procedural_memory[\\\"check_inventory\\\"](product_id)\\n        if stock > 0:\\n            return True, f\\\"Product {product_id} is in stock ({stock} units).\\\"\\n        return False, f\\\"Product {product_id} is out of stock.\\\"\\n\\n    def _plan_recommendation_strategy(self, user_id, user_query):\\n        # Simulates adaptive planning and decision-making (Multi-Strategy Planning)\\n        print(f\\\"[Planning] Determining recommendation strategy for {user_id} with query: '{user_query}'\\\")\\n        self.working_memory = {\\\"user_id\\\": user_id, \\\"query\\\": user_query}\\n        user_profile = self.user_profiles.get(user_id, {})\\n        user_preferences = user_profile.get(\\\"preferences\\\", {})\\n\\n        strategy = \\\"popular\\\"\\n        if \\\"budget\\\" in user_query.lower() or user_preferences.get(\\\"budget\\\"):\\n            strategy = \\\"price_sensitive\\\"\\n        elif \\\"fast delivery\\\" in user_query.lower():\\n            strategy = \\\"stock_priority\\\"\\n        elif user_preferences.get(\\\"category\\\"):\\n            strategy = \\\"personalized_category\\\"\\n        \\n        self.working_memory[\\\"strategy\\\"] = strategy\\n        print(f\\\"  Selected strategy: {strategy}\\\")\\n        return strategy\\n\\n    def _generate_recommendations(self, user_id, user_query):\\n        # Orchestrates LLM and tools to generate recommendations\\n        strategy = self._plan_recommendation_strategy(user_id, user_query)\\n        recommendations = []\\n        \\n        if strategy == \\\"personalized_category\\\":\\n            preferred_category = self.user_profiles[user_id][\\\"preferences\\\"].get(\\\"category\\\")\\n            llm_prompt = f\\\"Recommend products in the {preferred_category} category for {user_id}.\\\"\\n            llm_response = self._llm_inference(llm_prompt, self.working_memory)\\n            # In a real system, LLM would output product IDs, here we parse a simple string\\n            if \\\"Laptop Pro\\\" in llm_response: recommendations.append(\\\"P001\\\")\\n            if \\\"Gaming Headset\\\" in llm_response: recommendations.append(\\\"P005\\\")\\n            if \\\"Designer T-Shirt\\\" in llm_response: recommendations.append(\\\"P003\\\")\\n\\n        elif strategy == \\\"price_sensitive\\\":\\n            llm_prompt = f\\\"Recommend affordable products based on query '{user_query}'.\\\"\\n            llm_response = self._llm_inference(llm_prompt, self.working_memory)\\n            # Simplified: just pick a few cheap ones\\n            recommendations = [pid for pid, p in self.semantic_memory.items() if p[\\\"price\\\"] < 100]\\n            random.shuffle(recommendations)\\n            recommendations = recommendations[:3]\\n        else: # popular or stock_priority (simplified to popular for this demo)\\n            llm_prompt = f\\\"Recommend popular products based on query '{user_query}'.\\\"\\n            llm_response = self._llm_inference(llm_prompt, self.working_memory)\\n            recommendations = [\\\"P001\\\", \\\"P004\\\", \\\"P002\\\"] # Example popular items\\n        \\n        final_recommendations = []\\n        for rec_id in recommendations:\\n            is_valid, reason = self._verify_recommendation(rec_id) # Grounded & Iterative Planning\\n            if is_valid:\\n                details = self.procedural_memory[\\\"retrieve_reviews\\\"](rec_id)\\n                final_recommendations.append(f\\\"{details['name']} (${details['price']:.2f}) - Reviews: {', '.join(details['reviews'])} (Stock: {self.procedural_memory['check_inventory'](rec_id)})\\\")\\n            else:\\n                print(f\\\"  [Self-Correction] Skipping {rec_id}: {reason}\\\")\\n        \\n        # Output Generation\\n        return \\\"Here are some recommendations for you:\\\\n\\\" + \\\"\\\\n\\\".join(final_recommendations) if final_recommendations else \\\"Sorry, no suitable recommendations found.\\\"\\n\\n    def _learn_from_interaction(self, user_id, recommended, clicked_item):\\n        # Simulates continuous learning & self-improvement (Finetuning/Alignment)\\n        print(f\\\"[Learning] User {user_id} clicked on {clicked_item} from {recommended}.\\\")\\n        if user_id not in self.episodic_memory: self.episodic_memory[user_id] = []\\n        self.episodic_memory[user_id].append({\\\"recommended\\\": recommended, \\\"clicked\\\": clicked_item, \\\"timestamp\\\": time.time()})\\n\\n        if clicked_item and clicked_item in self.semantic_memory:\\n            clicked_category = self.semantic_memory[clicked_item][\\\"category\\\"]\\n            if user_id in self.user_profiles:\\n                self.user_profiles[user_id][\\\"preferences\\\"][\\\"category\\\"] = clicked_category\\n                print(f\\\"  Updated {user_id}'s preferred category to {clicked_category} based on click.\\\")\\n\\n    def run_simulation(self):\\n        print(\\\"--- E-commerce Agent Simulation Started ---\\\")\\n        user_id = \\\"user123\\\"\\n\\n        # Scenario 1: User asks for electronics recommendations\\n        user_query_1 = \\\"I'm looking for new electronics.\\\"\\n        print(f\\\"\\\\n[Scenario 1] User {user_id} asks: '{user_query_1}'\\\")\\n        recommendations_1 = self._generate_recommendations(user_id, user_query_1)\\n        print(f\\\"Agent's recommendations:\\\\n{recommendations_1}\\\")\\n        \\n        # Simulate user clicking on a recommended item\\n        clicked_item_1 = \\\"P005\\\" # Gaming Headset\\n        self._learn_from_interaction(user_id, recommendations_1, clicked_item_1)\\n        print(f\\\"User {user_id}'s updated profile: {self.user_profiles.get(user_id)}\\\")\\n\\n        # Scenario 2: User asks for an explanation of a product\\n        user_query_2 = \\\"Can you tell me more about P001?\\\"\\n        print(f\\\"\\\\n[Scenario 2] User {user_id} asks: '{user_query_2}'\\\")\\n        llm_explanation = self._llm_inference(user_query_2)\\n        print(f\\\"Agent's explanation: {llm_explanation}\\\")\\n\\n        # Scenario 3: User asks for budget-friendly items\\n        user_id_new = \\\"user456\\\"\\n        user_query_3 = \\\"Show me some affordable items.\\\"\\n        print(f\\\"\\\\n[Scenario 3] User {user_id_new} asks: '{user_query_3}'\\\")\\n        recommendations_3 = self._generate_recommendations(user_id_new, user_query_3)\\n        print(f\\\"Agent's recommendations:\\\\n{recommendations_3}\\\")\\n        \\n        print(\\\"\\\\n--- E-commerce Agent Simulation Finished ---\\\")\\n\\nif __name__ == \\\"__main__\\\":\\n    agent = ECommerceAgent()\\n    agent.run_simulation()\",\n",
      "\"import random\\nimport time\\n\\nclass FinancialAgent:\\n    def __init__(self):\\n        self.working_memory = {}\\n        self.episodic_memory = {} # Account transaction history, past advice\\n        self.semantic_memory = { # Financial knowledge, regulations\\n            \\\"investment_options\\\": [\\\"stocks\\\", \\\"bonds\\\", \\\"mutual_funds\\\", \\\"real_estate\\\"],\\n            \\\"fraud_patterns\\\": {\\\"large_unusual_purchase\\\": 1000, \\\"international_transaction_unusual\\\": True},\\n            \\\"budgeting_tips\\\": \\\"Track expenses, set savings goals, differentiate needs vs wants.\\\",\\n            \\\"savings_account_interest\\\": 0.01,\\n            \\\"risk_tolerance_low\\\": \\\"Invest in bonds and mutual funds.\\\",\\n            \\\"risk_tolerance_high\\\": \\\"Consider stocks and real estate.\\\"\\n        }\\n        self.procedural_memory = {\\n            \\\"query_transactions\\\": self._tool_transaction_db_query,\\n            \\\"assess_risk\\\": self._tool_risk_assessment,\\n            \\\"generate_budget\\\": self._tool_budget_planner\\n        }\\n        self.user_profiles = {\\n            \\\"client_A\\\": {\\\"balance\\\": 15000, \\\"spending_pattern\\\": {\\\"avg_monthly\\\": 1200, \\\"max_single\\\": 500}, \\\"risk_tolerance\\\": \\\"medium\\\", \\\"goals\\\": {\\\"retirement\\\": 500000}},\\n            \\\"client_B\\\": {\\\"balance\\\": 500, \\\"spending_pattern\\\": {\\\"avg_monthly\\\": 300, \\\"max_single\\\": 100}, \\\"risk_tolerance\\\": \\\"low\\\", \\\"goals\\\": {\\\"emergency_fund\\\": 1000}}\\n        }\\n        # Simulate a knowledge graph for relationships (simplified)\\n        self.knowledge_graph = {\\n            \\\"stocks\\\": {\\\"related\\\": [\\\"high_risk\\\", \\\"high_return\\\"]},\\n            \\\"bonds\\\": {\\\"related\\\": [\\\"low_risk\\\", \\\"low_return\\\"]},\\n            \\\"mutual_funds\\\": {\\\"related\\\": [\\\"diversified_risk\\\"]},\\n            \\\"retirement\\\": {\\\"related\\\": [\\\"long_term_goal\\\", \\\"compound_interest\\\"]}\\n        }\\n\\n    def _llm_inference(self, prompt, context=None):\\n        # Simulates LLM's core reasoning, intent understanding, and direct generation\\n        print(f\\\"  [LLM] Processing prompt: '{prompt}' with context: {context}\\\")\\n        if \\\"fraudulent\\\" in prompt.lower() and \\\"transaction\\\" in str(context).lower():\\n            transaction_id = context.get(\\\"transaction_id\\\", \\\"unknown\\\")\\n            if context.get(\\\"risk_score\\\", 0) > 0.7:\\n                return f\\\"Transaction {transaction_id} is highly suspicious due to its size and unusual category. Immediate action recommended.\\\"\\n            else:\\n                return f\\\"Transaction {transaction_id} appears normal based on current patterns. Monitoring advised.\\\"\\n        elif \\\"financial advice\\\" in prompt.lower() and \\\"goal\\\" in str(context).lower():\\n            goal = context[\\\"goal\\\"]\\n            risk = context.get(\\\"risk_tolerance\\\", \\\"medium\\\")\\n            if goal == \\\"retirement\\\" and risk == \\\"high\\\":\\n                return f\\\"To reach your {goal} goal with a {risk} risk tolerance, consider investing in a diversified portfolio of growth stocks and real estate funds. Ensure regular contributions.\\\"\\n            elif goal == \\\"emergency_fund\\\" and risk == \\\"low\\\":\\n                return f\\\"For your {goal} goal with a {risk} risk tolerance, focus on high-yield savings accounts and short-term bonds. Prioritize regular, automated savings.\\\"\\n            else:\\n                return f\\\"Based on your goal '{goal}' and risk '{risk}', I recommend a balanced approach combining mutual funds and a stable savings account.\\\"\\n        elif \\\"clarify\\\" in prompt.lower() or \\\"understand\\\" in prompt.lower():\\n            return \\\"Please tell me more about your financial query or the transaction you are concerned about.\\\"\\n        elif \\\"explain\\\" in prompt.lower() and \\\"stocks\\\" in prompt.lower():\\n            return f\\\"Stocks represent ownership in a company. They are generally associated with {', '.join(self.knowledge_graph.get('stocks', {}).get('related', []))}.\\\"\\n        return \\\"I am processing your request.\\\"\\n\\n    def _retrieve_financial_info(self, query):\\n        # Simulates RAG: Retrieves relevant info from semantic memory or knowledge graph\\n        print(f\\\"  [RAG] Retrieving financial info for: {query}\\\")\\n        results = [v for k, v in self.semantic_memory.items() if query.lower() in k.lower() or query.lower() in str(v).lower()]\\n        if not results and query in self.knowledge_graph:\\n            return f\\\"From knowledge graph: {query} is related to {', '.join(self.knowledge_graph[query].get('related', []))}.\\\"\\n        return results[0] if results else \\\"No specific financial information found.\\\"\\n\\n    def _tool_transaction_db_query(self, client_id, transaction_id):\\n        # Simulates querying a transaction database\\n        print(f\\\"  [Tool] Querying transaction DB for {transaction_id} of {client_id}\\\")\\n        # Simulate transaction data\\n        transactions = {\\n            \\\"T001\\\": {\\\"client_id\\\": \\\"client_A\\\", \\\"amount\\\": 150, \\\"category\\\": \\\"groceries\\\", \\\"timestamp\\\": time.time() - 3600},\\n            \\\"T002\\\": {\\\"client_id\\\": \\\"client_A\\\", \\\"amount\\\": 1200, \\\"category\\\": \\\"international_travel\\\", \\\"timestamp\\\": time.time() - 7200},\\n            \\\"T003\\\": {\\\"client_id\\\": \\\"client_B\\\", \\\"amount\\\": 50, \\\"category\\\": \\\"dining\\\", \\\"timestamp\\\": time.time() - 1800},\\n            \\\"T004\\\": {\\\"client_id\\\": \\\"client_B\\\", \\\"amount\\\": 600, \\\"category\\\": \\\"electronics\\\", \\\"timestamp\\\": time.time() - 10000},\\n        }\\n        return transactions.get(transaction_id) if transactions.get(transaction_id, {}).get(\\\"client_id\\\") == client_id else None\\n\\n    def _tool_risk_assessment(self, transaction_details, user_profile):\\n        # Simulates a fraud risk assessment model\\n        print(f\\\"  [Tool] Assessing risk for transaction: {transaction_details.get('transaction_id')}\\\")\\n        risk_score = 0.0\\n        if transaction_details[\\\"amount\\\"] > user_profile[\\\"spending_pattern\\\"][\\\"max_single\\\"] * 2:\\n            risk_score += 0.5 # unusually high amount\\n        if user_profile[\\\"spending_pattern\\\"].get(\\\"international_transaction_unusual\\\") and \\\"international\\\" in transaction_details[\\\"category\\\"]:\\n            risk_score += 0.4 # unusual international transaction\\n        return min(risk_score, 1.0) # Cap at 1.0\\n\\n    def _tool_budget_planner(self, income, expenses, goal_amount, current_savings=0):\\n        # Simulates a budgeting tool\\n        print(f\\\"  [Tool] Generating budget for income={income}, expenses={expenses}, goal={goal_amount}\\\")\\n        disposable_income = income - expenses\\n        if disposable_income <= 0: return \\\"Cannot create a positive budget with current income/expenses.\\\"\\n        \\n        monthly_savings_needed = (goal_amount - current_savings) / 12 # Simplified to 1 year for goal\\n        if monthly_savings_needed > disposable_income: \\n            return f\\\"To reach your goal of ${goal_amount} in a year, you need to save ${monthly_savings_needed:.2f} monthly, which exceeds your disposable income. Consider adjusting goal or expenses.\\\"\\n        else:\\n            return f\\\"Recommended monthly savings: ${monthly_savings_needed:.2f}. Remaining disposable income: ${disposable_income - monthly_savings_needed:.2f}.\\\"\\n\\n    def _verify_transaction_pattern(self, transaction, user_id):\\n        # Simulates verification and self-correction for fraud detection\\n        print(f\\\"  [Verification] Checking transaction {transaction.get('transaction_id')} against user patterns.\\\")\\n        user_profile = self.user_profiles.get(user_id)\\n        if not user_profile: return False, \\\"User profile not found.\\\"\\n\\n        risk_score = self.procedural_memory[\\\"assess_risk\\\"](transaction, user_profile)\\n        self.working_memory[\\\"risk_score\\\"] = risk_score\\n        \\n        if risk_score > 0.7: # High risk threshold\\n            return False, f\\\"High risk transaction detected (score: {risk_score:.2f}).\\\"\\n        elif risk_score > 0.4:\\n            return True, f\\\"Moderate risk transaction detected (score: {risk_score:.2f}). Monitoring recommended.\\\"\\n        return True, \\\"Transaction seems consistent with user patterns.\\\"\\n\\n    def _plan_fraud_investigation(self, client_id, transaction_id):\\n        # Simulates adaptive planning for fraud detection (Grounded & Iterative Planning)\\n        print(f\\\"[Planning] Starting fraud investigation for {transaction_id} for {client_id}\\\")\\n        self.working_memory = {\\\"client_id\\\": client_id, \\\"transaction_id\\\": transaction_id}\\n\\n        # Step 1: Retrieve transaction details (Tool Integration)\\n        transaction_details = self.procedural_memory[\\\"query_transactions\\\"](client_id, transaction_id)\\n        if not transaction_details:\\n            return \\\"Transaction not found or unauthorized access.\\\"\\n        self.working_memory[\\\"transaction_details\\\"] = transaction_details\\n        print(f\\\"  Retrieved transaction details: {transaction_details}\\\")\\n\\n        # Step 2: Verify against user patterns (Verification, Self-Correction)\\n        is_consistent, verification_feedback = self._verify_transaction_pattern(transaction_details, client_id)\\n        print(f\\\"  Verification result: {verification_feedback}\\\")\\n        \\n        # Step 3: LLM for final assessment and recommendation (Core Reasoning, Direct Generation)\\n        llm_prompt = f\\\"Is transaction {transaction_id} fraudulent? Context: {self.working_memory}\\\"\\n        llm_assessment = self._llm_inference(llm_prompt, self.working_memory)\\n        \\n        # Step 4: Store incident in episodic memory (Continuous Learning)\\n        if \\\"highly suspicious\\\" in llm_assessment.lower():\\n            if client_id not in self.episodic_memory: self.episodic_memory[client_id] = []\\n            self.episodic_memory[client_id].append({\\\"transaction_id\\\": transaction_id, \\\"status\\\": \\\"fraud_alert\\\", \\\"timestamp\\\": time.time()})\\n            # Simulate updating fraud patterns based on confirmed fraud (Learning)\\n            print(f\\\"  [Learning] Updating fraud patterns based on potential fraud for {client_id}.\\\")\\n        \\n        return llm_assessment\\n\\n    def _plan_financial_advice(self, client_id, goal):\\n        # Simulates hierarchical planning for financial advice\\n        print(f\\\"[Planning] Generating financial advice for {client_id} for goal: {goal}\\\")\\n        self.working_memory = {\\\"client_id\\\": client_id, \\\"goal\\\": goal}\\n        user_profile = self.user_profiles.get(client_id, {})\\n\\n        # Step 1: LLM for initial advice based on profile (Core Reasoning)\\n        llm_prompt = f\\\"Provide financial advice for {client_id} with goal '{goal}' and risk tolerance '{user_profile.get('risk_tolerance')}.\\\"\\n        initial_advice = self._llm_inference(llm_prompt, {\\\"goal\\\": goal, \\\"risk_tolerance\\\": user_profile.get(\\\"risk_tolerance\\\")})\\n        self.working_memory[\\\"initial_advice\\\"] = initial_advice\\n        print(f\\\"  Initial LLM advice: {initial_advice}\\\")\\n\\n        # Step 2: Integrate with budgeting tool if applicable (Tool Integration)\\n        if goal == \\\"emergency_fund\\\" and user_profile.get(\\\"balance\\\", 0) < user_profile.get(\\\"goals\\\", {}).get(\\\"emergency_fund\\\", 0):\\n            budget_plan = self.procedural_memory[\\\"generate_budget\\\"](\\n                income=user_profile.get(\\\"spending_pattern\\\", {}).get(\\\"avg_monthly\\\", 0) * 2, # Simplified income\\n                expenses=user_profile.get(\\\"spending_pattern\\\", {}).get(\\\"avg_monthly\\\", 0),\\n                goal_amount=user_profile.get(\\\"goals\\\", {}).get(\\\"emergency_fund\\\", 0),\\n                current_savings=user_profile.get(\\\"balance\\\", 0)\\n            )\\n            self.working_memory[\\\"budget_plan\\\"] = budget_plan\\n            initial_advice += f\\\"\\\\n  Budgeting suggestion: {budget_plan}\\\"\\n            print(f\\\"  Integrated budget plan: {budget_plan}\\\")\\n        \\n        # Step 3: Store advice in episodic memory (Experience-Based Learning)\\n        if client_id not in self.episodic_memory: self.episodic_memory[client_id] = []\\n        self.episodic_memory[client_id].append({\\\"goal\\\": goal, \\\"advice\\\": initial_advice, \\\"timestamp\\\": time.time()})\\n        print(\\\"  Advice finalized and stored in episodic memory.\\\")\\n\\n        return initial_advice\\n\\n    def _multi_agent_collaboration(self, client_id, query):\\n        # Simulates Multi-Agent Systems & Collaboration (FraudDetectionAgent and FinancialAdvisorAgent)\\n        print(f\\\"\\\\n[Multi-Agent] Client {client_id} has a query: '{query}'\\\")\\n        self.working_memory[\\\"client_id\\\"] = client_id\\n        self.working_memory[\\\"query\\\"] = query\\n\\n        # Intent Understanding by a central orchestrator (LLM)\\n        intent_llm_response = self._llm_inference(f\\\"Clarify intent for client {client_id} query: '{query}'\\\", self.working_memory)\\n        print(f\\\"  Central LLM for intent: {intent_llm_response}\\\")\\n\\n        if \\\"transaction\\\" in query.lower() or \\\"fraud\\\" in query.lower():\\n            print(\\\"  Delegating to Fraud Detection Agent...\\\")\\n            # Simulate the Fraud Detection Agent's role\\n            transaction_id = query.split(' ')[-1] if 'T' in query.split(' ')[-1] else 'T002' # Example\\n            self.working_memory[\\\"agent_role\\\"] = \\\"Fraud Detection\\\"\\n            result = self._plan_fraud_investigation(client_id, transaction_id)\\n            return f\\\"Fraud Detection Agent's Report: {result}\\\"\\n        elif \\\"financial\\\" in query.lower() or \\\"advice\\\" in query.lower() or \\\"invest\\\" in query.lower():\\n            print(\\\"  Delegating to Financial Advisor Agent...\\\")\\n            # Simulate the Financial Advisor Agent's role\\n            goal = \\\"retirement\\\" if \\\"retirement\\\" in query.lower() else \\\"emergency_fund\\\"\\n            self.working_memory[\\\"agent_role\\\"] = \\\"Financial Advisor\\\"\\n            result = self._plan_financial_advice(client_id, goal)\\n            return f\\\"Financial Advisor Agent's Advice: {result}\\\"\\n        else:\\n            return f\\\"I'm sorry, I couldn't understand the intent for '{query}'. Please rephrase.\\\"\\n\\n    def run_simulation(self):\\n        print(\\\"--- Banking Agent Simulation Started ---\\\")\\n\\n        # Scenario 1: Fraud Detection for client_A\\n        client_id_A = \\\"client_A\\\"\\n        transaction_id_A = \\\"T002\\\" # A potentially fraudulent transaction\\n        print(f\\\"\\\\n[Scenario 1] Client {client_id_A} has a suspicious transaction {transaction_id_A}.\\\")\\n        fraud_report_A = self._plan_fraud_investigation(client_id_A, transaction_id_A)\\n        print(f\\\"\\\\nFinal Fraud Report for {transaction_id_A}:\\\\n{fraud_report_A}\\\")\\n\\n        # Scenario 2: Financial Advice for client_A (Retirement goal)\\n        print(f\\\"\\\\n[Scenario 2] Client {client_id_A} seeks retirement advice.\\\")\\n        advice_A = self._plan_financial_advice(client_id_A, \\\"retirement\\\")\\n        print(f\\\"\\\\nFinal Financial Advice for {client_id_A}:\\\\n{advice_A}\\\")\\n\\n        # Scenario 3: Multi-Agent Collaboration for client_B (Emergency fund)\\n        client_id_B = \\\"client_B\\\"\\n        query_B = \\\"I need advice on saving for an emergency fund.\\\"\\n        print(f\\\"\\\\n[Scenario 3] Client {client_id_B} asks: '{query_B}'\\\")\\n        multi_agent_response_B = self._multi_agent_collaboration(client_id_B, query_B)\\n        print(f\\\"\\\\nMulti-Agent System Response:\\\\n{multi_agent_response_B}\\\")\\n\\n        # Scenario 4: User asks for explanation using RAG and KG\\n        print(\\\"\\\\n[Scenario 4] User asks to explain stocks.\\\")\\n        explanation = self._llm_inference(\\\"Explain stocks to me.\\\")\\n        print(f\\\"Agent's explanation: {explanation}\\\")\\n\\n        print(\\\"\\\\n--- Banking Agent Simulation Finished ---\\\")\\n\\nif __name__ == \\\"__main__\\\":\\n    agent = FinancialAgent()\\n    agent.run_simulation()\",\n",
      "]\n",
      "Error decoding JSON for pattern Comprehensive Black-Box Explainability and Analysis Framework: Expecting value: line 1 column 1 (char 0)\n",
      "Output content: json\n",
      "[\n",
      "    \"import numpy as np\\nimport pandas as pd\\nfrom sklearn.model_selection import train_test_split\\nfrom sklearn.ensemble import RandomForestClassifier\\nfrom sklearn.tree import DecisionTreeClassifier\\nimport lime\\nimport lime.lime_tabular\\nimport shap\\nimport random\\n\\nnp.random.seed(42)\\nn_samples = 1000\\ndata = {\\n    'credit_score': np.random.randint(300, 850, n_samples),\\n    'income_k': np.random.randint(20, 200, n_samples),\\n    'loan_amount_k': np.random.randint(5, 500, n_samples),\\n    'employment_years': np.random.randint(0, 30, n_samples),\\n    'debt_to_income_ratio': np.random.rand(n_samples) * 0.6,\\n    'has_mortgage': np.random.choice([0, 1], n_samples, p=[0.6, 0.4]),\\n    'num_credit_cards': np.random.randint(0, 10, n_samples)\\n}\\ndf = pd.DataFrame(data)\\n\\ndf['approved'] = ((df['credit_score'] > 650) & (df['income_k'] > 50) &\\n                  (df['loan_amount_k'] < 200) & (df['debt_to_income_ratio'] < 0.3) |\\n                  (df['credit_score'] > 750) & (df['income_k'] > 30) &\\n                  (df['loan_amount_k'] < 300)).astype(int)\\n\\ndf['approved'] = df.apply(lambda row: 1 - row['approved'] if np.random.rand() < 0.1 else row['approved'], axis=1)\\n\\nX = df.drop('approved', axis=1)\\ny = df['approved']\\nfeature_names = X.columns.tolist()\\nclass_names = ['Rejected', 'Approved']\\n\\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\\n\\nblack_box_model = RandomForestClassifier(n_estimators=100, random_state=42, max_depth=10)\\nblack_box_model.fit(X_train, y_train)\\nprint(\\\"Black-Box Model (RandomForest) Accuracy:\\\", black_box_model.score(X_test, y_test))\\n\\nglobal_surrogate_model = DecisionTreeClassifier(max_depth=5, random_state=42)\\nglobal_surrogate_model.fit(X_train, black_box_model.predict(X_train))\\n\\ndef explain_instance(instance_idx):\\n    instance = X_test.iloc[instance_idx]\\n    print(f\\\"\\\\n--- Local Explanation for Instance {instance_idx} (Loan Application) ---\\\")\\n    print(\\\"Instance features:\\\", instance.to_dict())\\n    prediction = black_box_model.predict(instance.to_frame().T)[0]\\n    prediction_proba = black_box_model.predict_proba(instance.to_frame().T)[0]\\n    print(f\\\"Black-Box Model Prediction: {class_names[prediction]} (Probabilities: {prediction_proba})\\\")\\n\\n    explainer_lime = lime.lime_tabular.LimeTabularExplainer(\\n        training_data=X_train.values,\\n        feature_names=feature_names,\\n        class_names=class_names,\\n        mode='classification'\\n    )\\n    exp_lime = explainer_lime.explain_instance(\\n        data_row=instance.values,\\n        predict_fn=black_box_model.predict_proba,\\n        num_features=len(feature_names)\\n    )\\n    print(\\\"\\\\nLIME Explanation (Feature Importance for this prediction):\\\")\\n    for feature, weight in exp_lime.as_list():\\n        print(f\\\"  {feature}: {weight:.4f}\\\")\\n\\n    explainer_shap = shap.TreeExplainer(black_box_model)\\n    shap_values = explainer_shap.shap_values(instance)\\n    print(\\\"\\\\nSHAP Explanation (Feature Contribution to this prediction):\\\")\\n    if isinstance(shap_values, list):\\n        shap_values_to_print = shap_values[1] if len(shap_values) > 1 else shap_values[0]\\n    else:\\n        shap_values_to_print = shap_values\\n    for i, feature in enumerate(feature_names):\\n        print(f\\\"  {feature}: {shap_values_to_print[i]:.4f}\\\")\\n\\n    local_rules = []\\n    if prediction == 1:\\n        if instance['credit_score'] > 700:\\n            local_rules.append(\\\"IF credit_score > 700 THEN likely Approved\\\")\\n        if instance['income_k'] > 80 and instance['debt_to_income_ratio'] < 0.25:\\n            local_rules.append(\\\"IF income_k > 80 AND debt_to_income_ratio < 0.25 THEN likely Approved\\\")\\n    else:\\n        if instance['credit_score'] < 600:\\n            local_rules.append(\\\"IF credit_score < 600 THEN likely Rejected\\\")\\n        if instance['loan_amount_k'] > 300 and instance['debt_to_income_ratio'] > 0.4:\\n            local_rules.append(\\\"IF loan_amount_k > 300 AND debt_to_income_ratio > 0.4 THEN likely Rejected\\\")\\n    print(\\\"\\\\nLocal Rule-Based Explanation (Qualitative Insights - Simplified):\\\")\\n    if local_rules:\\n        for rule in local_rules:\\n            print(f\\\"  - {rule}\\\")\\n    else:\\n        print(\\\"  No specific simple local rules found for this instance.\\\")\\n\\ndef generate_counterfactual(instance_idx, desired_prediction_class=1):\\n    instance = X_test.iloc[instance_idx].copy()\\n    original_prediction = black_box_model.predict(instance.to_frame().T)[0]\\n    print(f\\\"\\\\n--- Counterfactual Explanation for Instance {instance_idx} ---\\\")\\n    print(f\\\"Original Prediction: {class_names[original_prediction]}\\\")\\n    if original_prediction == desired_prediction_class:\\n        print(f\\\"Instance already predicts {class_names[desired_prediction_class]}. No counterfactual needed.\\\")\\n        return\\n\\n    temp_instance = instance.copy()\\n    changes = {}\\n    \\n    if temp_instance['credit_score'] < 700:\\n        temp_instance['credit_score'] = min(850, temp_instance['credit_score'] + 50)\\n        changes['credit_score'] = temp_instance['credit_score']\\n        if black_box_model.predict(temp_instance.to_frame().T)[0] == desired_prediction_class:\\n            print(f\\\"Minimal change: Increase credit_score to {changes['credit_score']}. New Prediction: {class_names[desired_prediction_class]}\\\")\\n            return\\n\\n    temp_instance = instance.copy()\\n    if temp_instance['income_k'] < 100:\\n        temp_instance['income_k'] = min(200, temp_instance['income_k'] + 30)\\n        changes['income_k'] = temp_instance['income_k']\\n        if black_box_model.predict(temp_instance.to_frame().T)[0] == desired_prediction_class:\\n            print(f\\\"Minimal change: Increase income_k to {changes['income_k']}. New Prediction: {class_names[desired_prediction_class]}\\\")\\n            return\\n\\n    temp_instance = instance.copy()\\n    if temp_instance['debt_to_income_ratio'] > 0.3:\\n        temp_instance['debt_to_income_ratio'] = max(0.1, temp_instance['debt_to_income_ratio'] - 0.1)\\n        changes['debt_to_income_ratio'] = temp_instance['debt_to_income_ratio']\\n        if black_box_model.predict(temp_instance.to_frame().T)[0] == desired_prediction_class:\\n            print(f\\\"Minimal change: Decrease debt_to_income_ratio to {changes['debt_to_income_ratio']:.2f}. New Prediction: {class_names[desired_prediction_class]}\\\")\\n            return\\n            \\n    print(\\\"Could not find a simple counterfactual by changing one or two features significantly.\\\")\\n    print(\\\"Consider a more complex counterfactual search or multiple feature changes.\\\")\\n\\ndef subgroup_divergence_analysis():\\n    print(\\\"\\\\n--- Subgroup Divergence Analysis (Simulated) ---\\\")\\n    \\n    predictions = black_box_model.predict(X_test)\\n    is_misclassified = (predictions != y_test).astype(int)\\n    \\n    if is_misclassified.sum() == 0:\\n        print(\\\"No misclassified instances in the test set. Model performs perfectly.\\\")\\n        return\\n\\n    dt_analyzer = DecisionTreeClassifier(max_depth=3, random_state=42)\\n    dt_analyzer.fit(X_test, is_misclassified)\\n\\n    print(\\\"\\\\nPotential Divergent Subgroups (Characterized by Decision Tree on Misclassified Instances):\\\")\\n    \\n    tree_rules = []\\n    def get_rules(tree, feature_names, node_index=0, current_rule=\\\"\\\"):\\n        if tree.children_left[node_index] == tree.children_right[node_index]:\\n            if tree.n_node_samples[node_index] > 5:\\n                leaf_indices = X_test.index[dt_analyzer.apply(X_test) == node_index]\\n                if not leaf_indices.empty:\\n                    leaf_misclassified_count = is_misclassified.loc[leaf_indices].sum()\\n                    leaf_total_count = len(leaf_indices)\\n                    misclass_rate = leaf_misclassified_count / leaf_total_count\\n                    \\n                    overall_misclass_rate = is_misclassified.mean()\\n                    if misclass_rate > (overall_misclass_rate * 1.5) and leaf_total_count > 10:\\n                        tree_rules.append(f\\\"{current_rule} (N={leaf_total_count}, Misclass Rate={misclass_rate:.2f})\\\")\\n            return\\n\\n        feature = feature_names[tree.feature[node_index]]\\n        threshold = tree.threshold[node_index]\\n\\n        left_rule = f\\\"{current_rule} AND {feature} <= {threshold:.2f}\\\" if current_rule else f\\\"{feature} <= {threshold:.2f}\\\"\\n        get_rules(tree, feature_names, tree.children_left[node_index], left_rule)\\n\\n        right_rule = f\\\"{current_rule} AND {feature} > {threshold:.2f}\\\" if current_rule else f\\\"{feature} > {threshold:.2f}\\\"\\n        get_rules(tree, feature_names, tree.children_right[node_index], right_rule)\\n\\n    get_rules(dt_analyzer.tree_, feature_names)\\n\\n    if tree_rules:\\n        for rule in tree_rules:\\n            print(f\\\"- {rule}\\\")\\n    else:\\n        print(\\\"No strongly divergent subgroups identified with this simple analysis.\\\")\\n\\ndef interactive_exploration():\\n    print(\\\"\\\\n--- Interactive Explanation Console (Banking Loan Approval) ---\\\")\\n    while True:\\n        print(\\\"\\\\nSelect an action:\\\")\\n        print(\\\"1. Get local explanations for a specific loan application\\\")\\n        print(\\\"2. Generate a counterfactual explanation\\\")\\n        print(\\\"3. Perform subgroup divergence analysis\\\")\\n        print(\\\"4. View global surrogate model insights\\\")\\n        print(\\\"5. Exit\\\")\\n\\n        choice = input(\\\"Enter choice (1-5): \\\")\\n\\n        if choice == '1':\\n            try:\\n                idx = int(input(f\\\"Enter test instance index (0 to {len(X_test)-1}): \\\"))\\n                if 0 <= idx < len(X_test):\\n                    explain_instance(idx)\\n                else:\\n                    print(\\\"Invalid index.\\\")\\n            except ValueError:\\n                print(\\\"Invalid input.\\\")\\n        elif choice == '2':\\n            try:\\n                idx = int(input(f\\\"Enter test instance index for counterfactual (0 to {len(X_test)-1}): \\\"))\\n                if 0 <= idx < len(X_test):\\n                    generate_counterfactual(idx)\\n                else:\\n                    print(\\\"Invalid index.\\\")\\n            except ValueError:\\n                print(\\\"Invalid input.\\\")\\n        elif choice == '3':\\n            subgroup_divergence_analysis()\\n        elif choice == '4':\\n            print(\\\"\\\\n--- Global Understanding (Decision Tree Surrogate) ---\\\")\\n            print(\\\"Top features for global surrogate:\\\", global_surrogate_model.feature_importances_)\\n            print(\\\"Example global rule path (simplified): If credit_score <= 675.5 then predict Rejected\\\")\\n        elif choice == '5':\\n            print(\\\"Exiting interactive exploration.\\\")\\n            break\\n        else:\\n            print(\\\"Invalid choice. Please try again.\\\")\\n\\ninteractive_exploration()\",\n",
      "    \"import numpy as np\\nimport pandas as pd\\nfrom sklearn.model_selection import train_test_split\\nfrom sklearn.neural_network import MLPClassifier\\nfrom sklearn.linear_model import LogisticRegression\\nfrom sklearn.tree import DecisionTreeClassifier\\nimport lime\\nimport lime.lime_tabular\\nimport shap\\nimport random\\n\\nnp.random.seed(43)\\nn_samples = 1200\\ndata = {\\n    'age': np.random.randint(18, 85, n_samples),\\n    'bmi': np.random.uniform(18.0, 40.0, n_samples),\\n    'blood_pressure_sys': np.random.randint(90, 180, n_samples),\\n    'cholesterol_mgdl': np.random.randint(120, 300, n_samples),\\n    'glucose_mgdl': np.random.randint(70, 250, n_samples),\\n    'smoking_history': np.random.choice([0, 1], n_samples, p=[0.7, 0.3]),\\n    'family_history': np.random.choice([0, 1], n_samples, p=[0.6, 0.4]),\\n    'exercise_hours_week': np.random.uniform(0, 10, n_samples)\\n}\\ndf = pd.DataFrame(data)\\n\\ndf['disease_present'] = ((df['age'] > 60) & (df['cholesterol_mgdl'] > 200) & (df['blood_pressure_sys'] > 140) |\\n                         (df['bmi'] > 30) & (df['glucose_mgdl'] > 150) & (df['smoking_history'] == 1)).astype(int)\\n\\ndf['disease_present'] = df.apply(lambda row: 1 - row['disease_present'] if np.random.rand() < 0.15 else row['disease_present'], axis=1)\\n\\nX = df.drop('disease_present', axis=1)\\ny = df['disease_present']\\nfeature_names = X.columns.tolist()\\nclass_names = ['No Disease', 'Disease Present']\\n\\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=43)\\n\\nblack_box_model = MLPClassifier(hidden_layer_sizes=(100, 50), max_iter=300, random_state=43, early_stopping=True, n_iter_no_change=10)\\nblack_box_model.fit(X_train, y_train)\\nprint(\\\"Black-Box Model (MLPClassifier) Accuracy:\\\", black_box_model.score(X_test, y_test))\\n\\nglobal_surrogate_model = LogisticRegression(random_state=43, solver='liblinear')\\nglobal_surrogate_model.fit(X_train, black_box_model.predict(X_train))\\n\\ndef explain_instance(instance_idx):\\n    instance = X_test.iloc[instance_idx]\\n    print(f\\\"\\\\n--- Local Explanation for Instance {instance_idx} (Patient Diagnosis) ---\\\")\\n    print(\\\"Instance features:\\\", instance.to_dict())\\n    prediction = black_box_model.predict(instance.to_frame().T)[0]\\n    prediction_proba = black_box_model.predict_proba(instance.to_frame().T)[0]\\n    print(f\\\"Black-Box Model Prediction: {class_names[prediction]} (Probabilities: {prediction_proba})\\\")\\n\\n    explainer_lime = lime.lime_tabular.LimeTabularExplainer(\\n        training_data=X_train.values,\\n        feature_names=feature_names,\\n        class_names=class_names,\\n        mode='classification'\\n    )\\n    exp_lime = explainer_lime.explain_instance(\\n        data_row=instance.values,\\n        predict_fn=black_box_model.predict_proba,\\n        num_features=len(feature_names)\\n    )\\n    print(\\\"\\\\nLIME Explanation (Feature Importance for this prediction):\\\")\\n    for feature, weight in exp_lime.as_list():\\n        print(f\\\"  {feature}: {weight:.4f}\\\")\\n\\n    explainer_shap = shap.KernelExplainer(black_box_model.predict_proba, X_train)\\n    shap_values = explainer_shap.shap_values(instance)\\n    print(\\\"\\\\nSHAP Explanation (Feature Contribution to this prediction):\\\")\\n    if isinstance(shap_values, list):\\n        shap_values_to_print = shap_values[1] if len(shap_values) > 1 else shap_values[0]\\n    else:\\n        shap_values_to_print = shap_values\\n    for i, feature in enumerate(feature_names):\\n        print(f\\\"  {feature}: {shap_values_to_print[i]:.4f}\\\")\\n\\n    local_rules = []\\n    if prediction == 1:\\n        if instance['age'] > 65 and instance['cholesterol_mgdl'] > 220:\\n            local_rules.append(\\\"IF age > 65 AND cholesterol_mgdl > 220 THEN likely Disease Present\\\")\\n        if instance['glucose_mgdl'] > 180 or (instance['bmi'] > 35 and instance['smoking_history'] == 1):\\n            local_rules.append(\\\"IF glucose_mgdl > 180 OR (bmi > 35 AND smoking_history is present) THEN likely Disease Present\\\")\\n    else:\\n        if instance['age'] < 40 and instance['cholesterol_mgdl'] < 180:\\n            local_rules.append(\\\"IF age < 40 AND cholesterol_mgdl < 180 THEN likely No Disease\\\")\\n        if instance['exercise_hours_week'] > 5 and instance['smoking_history'] == 0:\\n            local_rules.append(\\\"IF exercise_hours_week > 5 AND smoking_history is absent THEN likely No Disease\\\")\\n    print(\\\"\\\\nLocal Rule-Based Explanation (Qualitative Insights - Simplified):\\\")\\n    if local_rules:\\n        for rule in local_rules:\\n            print(f\\\"  - {rule}\\\")\\n    else:\\n        print(\\\"  No specific simple local rules found for this instance.\\\")\\n\\ndef generate_counterfactual(instance_idx, desired_prediction_class=0):\\n    instance = X_test.iloc[instance_idx].copy()\\n    original_prediction = black_box_model.predict(instance.to_frame().T)[0]\\n    print(f\\\"\\\\n--- Counterfactual Explanation for Instance {instance_idx} ---\\\")\\n    print(f\\\"Original Prediction: {class_names[original_prediction]}\\\")\\n    if original_prediction == desired_prediction_class:\\n        print(f\\\"Instance already predicts {class_names[desired_prediction_class]}. No counterfactual needed.\\\")\\n        return\\n\\n    temp_instance = instance.copy()\\n    \\n    if temp_instance['glucose_mgdl'] > 120:\\n        temp_instance['glucose_mgdl'] = max(70, temp_instance['glucose_mgdl'] - 50)\\n        if black_box_model.predict(temp_instance.to_frame().T)[0] == desired_prediction_class:\\n            print(f\\\"Minimal change: Decrease glucose_mgdl to {temp_instance['glucose_mgdl']}. New Prediction: {class_names[desired_prediction_class]}\\\")\\n            return\\n        temp_instance = instance.copy()\\n\\n    if temp_instance['cholesterol_mgdl'] > 200:\\n        temp_instance['cholesterol_mgdl'] = max(120, temp_instance['cholesterol_mgdl'] - 40)\\n        if black_box_model.predict(temp_instance.to_frame().T)[0] == desired_prediction_class:\\n            print(f\\\"Minimal change: Decrease cholesterol_mgdl to {temp_instance['cholesterol_mgdl']}. New Prediction: {class_names[desired_prediction_class]}\\\")\\n            return\\n        temp_instance = instance.copy()\\n\\n    if temp_instance['smoking_history'] == 1:\\n        temp_instance['smoking_history'] = 0\\n        if black_box_model.predict(temp_instance.to_frame().T)[0] == desired_prediction_class:\\n            print(f\\\"Minimal change: Stop smoking. New Prediction: {class_names[desired_prediction_class]}\\\")\\n            return\\n        temp_instance = instance.copy()\\n\\n    if temp_instance['exercise_hours_week'] < 5:\\n        temp_instance['exercise_hours_week'] = min(10, temp_instance['exercise_hours_week'] + 3)\\n        if black_box_model.predict(temp_instance.to_frame().T)[0] == desired_prediction_class:\\n            print(f\\\"Minimal change: Increase exercise_hours_week to {temp_instance['exercise_hours_week']:.1f}. New Prediction: {class_names[desired_prediction_class]}\\\")\\n            return\\n        temp_instance = instance.copy()\\n            \\n    print(\\\"Could not find a simple counterfactual by changing one or two key modifiable features.\\\")\\n    print(\\\"Consider a more complex counterfactual search or multiple feature changes.\\\")\\n\\ndef subgroup_divergence_analysis():\\n    print(\\\"\\\\n--- Subgroup Divergence Analysis (Simulated) ---\\\")\\n    predictions = black_box_model.predict(X_test)\\n    is_misclassified = (predictions != y_test).astype(int)\\n    \\n    if is_misclassified.sum() == 0:\\n        print(\\\"No misclassified instances in the test set. Model performs perfectly.\\\")\\n        return\\n\\n    dt_analyzer = DecisionTreeClassifier(max_depth=3, random_state=43)\\n    dt_analyzer.fit(X_test, is_misclassified)\\n\\n    print(\\\"\\\\nPotential Divergent Subgroups (Characterized by Decision Tree on Misclassified Instances):\\\")\\n    \\n    tree_rules = []\\n    def get_rules(tree, feature_names, node_index=0, current_rule=\\\"\\\"):\\n        if tree.children_left[node_index] == tree.children_right[node_index]:\\n            if tree.n_node_samples[node_index] > 5:\\n                leaf_indices = X_test.index[dt_analyzer.apply(X_test) == node_index]\\n                if not leaf_indices.empty:\\n                    leaf_misclassified_count = is_misclassified.loc[leaf_indices].sum()\\n                    leaf_total_count = len(leaf_indices)\\n                    misclass_rate = leaf_misclassified_count / leaf_total_count\\n                    \\n                    overall_misclass_rate = is_misclassified.mean()\\n                    if misclass_rate > (overall_misclass_rate * 1.5) and leaf_total_count > 10:\\n                        tree_rules.append(f\\\"{current_rule} (N={leaf_total_count}, Misclass Rate={misclass_rate:.2f})\\\")\\n            return\\n\\n        feature = feature_names[tree.feature[node_index]]\\n        threshold = tree.threshold[node_index]\\n\\n        left_rule = f\\\"{current_rule} AND {feature} <= {threshold:.2f}\\\" if current_rule else f\\\"{feature} <= {threshold:.2f}\\\"\\n        get_rules(tree, feature_names, tree.children_left[node_index], left_rule)\\n\\n        right_rule = f\\\"{current_rule} AND {feature} > {threshold:.2f}\\\" if current_rule else f\\\"{feature} > {threshold:.2f}\\\"\\n        get_rules(tree, feature_names, tree.children_right[node_index], right_rule)\\n\\n    get_rules(dt_analyzer.tree_, feature_names)\\n\\n    if tree_rules:\\n        for rule in tree_rules:\\n            print(f\\\"- {rule}\\\")\\n    else:\\n        print(\\\"No strongly divergent subgroups identified with this simple analysis.\\\")\\n\\ndef interactive_exploration():\\n    print(\\\"\\\\n--- Interactive Explanation Console (Healthcare Disease Diagnosis) ---\\\")\\n    while True:\\n        print(\\\"\\\\nSelect an action:\\\")\\n        print(\\\"1. Get local explanations for a specific patient\\\")\\n        print(\\\"2. Generate a counterfactual explanation (e.g., how to get 'No Disease')\\\")\\n        print(\\\"3. Perform subgroup divergence analysis\\\")\\n        print(\\\"4. View global surrogate model insights\\\")\\n        print(\\\"5. Exit\\\")\\n\\n        choice = input(\\\"Enter choice (1-5): \\\")\\n\\n        if choice == '1':\\n            try:\\n                idx = int(input(f\\\"Enter test instance index (0 to {len(X_test)-1}): \\\"))\\n                if 0 <= idx < len(X_test):\\n                    explain_instance(idx)\\n                else:\\n                    print(\\\"Invalid index.\\\")\\n            except ValueError:\\n                print(\\\"Invalid input.\\\")\\n        elif choice == '2':\\n            try:\\n                idx = int(input(f\\\"Enter test instance index for counterfactual (0 to {len(X_test)-1}): \\\"))\\n                if 0 <= idx < len(X_test):\\n                    generate_counterfactual(idx)\\n                else:\\n                    print(\\\"Invalid index.\\\")\\n            except ValueError:\\n                print(\\\"Invalid input.\\\")\\n        elif choice == '3':\\n            subgroup_divergence_analysis()\\n        elif choice == '4':\\n            print(\\\"\\\\n--- Global Understanding (Logistic Regression Surrogate) ---\\\")\\n            print(\\\"Global surrogate coefficients (feature importance):\\\")\\n            for f, coef in zip(feature_names, global_surrogate_model.coef_[0]):\\n                print(f\\\"  {f}: {coef:.4f}\\\")\\n        elif choice == '5':\\n            print(\\\"Exiting interactive exploration.\\\")\\n            break\\n        else:\\n            print(\\\"Invalid choice. Please try again.\\\")\\n\\ninteractive_exploration()\",\n",
      "    \"import numpy as np\\nimport pandas as pd\\nfrom sklearn.model_selection import train_test_split\\nimport xgboost as xgb\\nfrom sklearn.ensemble import GradientBoostingClassifier\\nfrom sklearn.tree import DecisionTreeClassifier\\nimport lime\\nimport lime.lime_tabular\\nimport shap\\nimport random\\n\\nnp.random.seed(44)\\nn_samples = 1500\\ndata = {\\n    'age': np.random.randint(18, 70, n_samples),\\n    'num_purchases_last_year': np.random.randint(0, 50, n_samples),\\n    'avg_purchase_value': np.random.uniform(10, 500, n_samples),\\n    'website_visits_last_month': np.random.randint(0, 100, n_samples),\\n    'customer_service_calls_last_year': np.random.randint(0, 10, n_samples),\\n    'days_since_last_purchase': np.random.randint(0, 365, n_samples),\\n    'has_subscription': np.random.choice([0, 1], n_samples, p=[0.7, 0.3]),\\n    'promo_clicks_last_month': np.random.randint(0, 20, n_samples)\\n}\\ndf = pd.DataFrame(data)\\n\\ndf['churn'] = ((df['days_since_last_purchase'] > 90) & (df['num_purchases_last_year'] < 5) &\\n               (df['customer_service_calls_last_year'] > 3) |\\n               (df['website_visits_last_month'] < 5) & (df['has_subscription'] == 0) &\\n               (df['avg_purchase_value'] < 50)).astype(int)\\n\\ndf['churn'] = df.apply(lambda row: 1 - row['churn'] if np.random.rand() < 0.12 else row['churn'], axis=1)\\n\\nX = df.drop('churn', axis=1)\\ny = df['churn']\\nfeature_names = X.columns.tolist()\\nclass_names = ['Retain', 'Churn']\\n\\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=44)\\n\\nblack_box_model = xgb.XGBClassifier(n_estimators=100, use_label_encoder=False, eval_metric='logloss', random_state=44)\\nblack_box_model.fit(X_train, y_train)\\nprint(\\\"Black-Box Model (XGBoost) Accuracy:\\\", black_box_model.score(X_test, y_test))\\n\\nglobal_surrogate_model = GradientBoostingClassifier(n_estimators=50, max_depth=3, random_state=44)\\nglobal_surrogate_model.fit(X_train, black_box_model.predict(X_train))\\n\\ndef explain_instance(instance_idx):\\n    instance = X_test.iloc[instance_idx]\\n    print(f\\\"\\\\n--- Local Explanation for Instance {instance_idx} (Customer Churn) ---\\\")\\n    print(\\\"Instance features:\\\", instance.to_dict())\\n    prediction = black_box_model.predict(instance.to_frame().T)[0]\\n    prediction_proba = black_box_model.predict_proba(instance.to_frame().T)[0]\\n    print(f\\\"Black-Box Model Prediction: {class_names[prediction]} (Probabilities: {prediction_proba})\\\")\\n\\n    explainer_lime = lime.lime_tabular.LimeTabularExplainer(\\n        training_data=X_train.values,\\n        feature_names=feature_names,\\n        class_names=class_names,\\n        mode='classification'\\n    )\\n    exp_lime = explainer_lime.explain_instance(\\n        data_row=instance.values,\\n        predict_fn=black_box_model.predict_proba,\\n        num_features=len(feature_names)\\n    )\\n    print(\\\"\\\\nLIME Explanation (Feature Importance for this prediction):\\\")\\n    for feature, weight in exp_lime.as_list():\\n        print(f\\\"  {feature}: {weight:.4f}\\\")\\n\\n    explainer_shap = shap.TreeExplainer(black_box_model)\\n    shap_values = explainer_shap.shap_values(instance)\\n    print(\\\"\\\\nSHAP Explanation (Feature Contribution to this prediction):\\\")\\n    if isinstance(shap_values, list):\\n        shap_values_to_print = shap_values[1] if len(shap_values) > 1 else shap_values[0]\\n    else:\\n        shap_values_to_print = shap_values\\n    for i, feature in enumerate(feature_names):\\n        print(f\\\"  {feature}: {shap_values_to_print[i]:.4f}\\\")\\n\\n    local_rules = []\\n    if prediction == 1:\\n        if instance['days_since_last_purchase'] > 120 and instance['num_purchases_last_year'] < 3:\\n            local_rules.append(\\\"IF days_since_last_purchase > 120 AND num_purchases_last_year < 3 THEN likely Churn\\\")\\n        if instance['customer_service_calls_last_year'] > 5 and instance['has_subscription'] == 0:\\n            local_rules.append(\\\"IF customer_service_calls_last_year > 5 AND no subscription THEN likely Churn\\\")\\n    else:\\n        if instance['website_visits_last_month'] > 20 and instance['avg_purchase_value'] > 100:\\n            local_rules.append(\\\"IF website_visits_last_month > 20 AND avg_purchase_value > 100 THEN likely Retain\\\")\\n        if instance['has_subscription'] == 1 and instance['promo_clicks_last_month'] > 5:\\n            local_rules.append(\\\"IF has_subscription AND promo_clicks_last_month > 5 THEN likely Retain\\\")\\n    print(\\\"\\\\nLocal Rule-Based Explanation (Qualitative Insights - Simplified):\\\")\\n    if local_rules:\\n        for rule in local_rules:\\n            print(f\\\"  - {rule}\\\")\\n    else:\\n        print(\\\"  No specific simple local rules found for this instance.\\\")\\n\\ndef generate_counterfactual(instance_idx, desired_prediction_class=0):\\n    instance = X_test.iloc[instance_idx].copy()\\n    original_prediction = black_box_model.predict(instance.to_frame().T)[0]\\n    print(f\\\"\\\\n--- Counterfactual Explanation for Instance {instance_idx} ---\\\")\\n    print(f\\\"Original Prediction: {class_names[original_prediction]}\\\")\\n    if original_prediction == desired_prediction_class:\\n        print(f\\\"Instance already predicts {class_names[desired_prediction_class]}. No counterfactual needed.\\\")\\n        return\\n\\n    temp_instance = instance.copy()\\n    \\n    if temp_instance['website_visits_last_month'] < 15:\\n        temp_instance['website_visits_last_month'] = min(100, temp_instance['website_visits_last_month'] + 10)\\n        if black_box_model.predict(temp_instance.to_frame().T)[0] == desired_prediction_class:\\n            print(f\\\"Minimal change: Increase website_visits_last_month to {temp_instance['website_visits_last_month']}. New Prediction: {class_names[desired_prediction_class]}\\\")\\n            return\\n        temp_instance = instance.copy()\\n\\n    if temp_instance['days_since_last_purchase'] > 60:\\n        temp_instance['days_since_last_purchase'] = 30\\n        if black_box_model.predict(temp_instance.to_frame().T)[0] == desired_prediction_class:\\n            print(f\\\"Minimal change: Make a new purchase (days_since_last_purchase=30). New Prediction: {class_names[desired_prediction_class]}\\\")\\n            return\\n        temp_instance = instance.copy()\\n\\n    if temp_instance['has_subscription'] == 0:\\n        temp_instance['has_subscription'] = 1\\n        if black_box_model.predict(temp_instance.to_frame().T)[0] == desired_prediction_class:\\n            print(f\\\"Minimal change: Subscribe to a service. New Prediction: {class_names[desired_prediction_class]}\\\")\\n            return\\n        temp_instance = instance.copy()\\n\\n    if temp_instance['promo_clicks_last_month'] < 5:\\n        temp_instance['promo_clicks_last_month'] = min(20, temp_instance['promo_clicks_last_month'] + 5)\\n        if black_box_model.predict(temp_instance.to_frame().T)[0] == desired_prediction_class:\\n            print(f\\\"Minimal change: Increase promo_clicks_last_month to {temp_instance['promo_clicks_last_month']}. New Prediction: {class_names[desired_prediction_class]}\\\")\\n            return\\n        temp_instance = instance.copy()\\n            \\n    print(\\\"Could not find a simple counterfactual by changing one or two key modifiable features.\\\")\\n    print(\\\"Consider a more complex counterfactual search or multiple feature changes.\\\")\\n\\ndef subgroup_divergence_analysis():\\n    print(\\\"\\\\n--- Subgroup Divergence Analysis (Simulated) ---\\\")\\n    predictions = black_box_model.predict(X_test)\\n    is_misclassified = (predictions != y_test).astype(int)\\n    \\n    if is_misclassified.sum() == 0:\\n        print(\\\"No misclassified instances in the test set. Model performs perfectly.\\\")\\n        return\\n\\n    dt_analyzer = DecisionTreeClassifier(max_depth=3, random_state=44)\\n    dt_analyzer.fit(X_test, is_misclassified)\\n\\n    print(\\\"\\\\nPotential Divergent Subgroups (Characterized by Decision Tree on Misclassified Instances):\\\")\\n    \\n    tree_rules = []\\n    def get_rules(tree, feature_names, node_index=0, current_rule=\\\"\\\"):\\n        if tree.children_left[node_index] == tree.children_right[node_index]:\\n            if tree.n_node_samples[node_index] > 5:\\n                leaf_indices = X_test.index[dt_analyzer.apply(X_test) == node_index]\\n                if not leaf_indices.empty:\\n                    leaf_misclassified_count = is_misclassified.loc[leaf_indices].sum()\\n                    leaf_total_count = len(leaf_indices)\\n                    misclass_rate = leaf_misclassified_count / leaf_total_count\\n                    \\n                    overall_misclass_rate = is_misclassified.mean()\\n                    if misclass_rate > (overall_misclass_rate * 1.5) and leaf_total_count > 10:\\n                        tree_rules.append(f\\\"{current_rule} (N={leaf_total_count}, Misclass Rate={misclass_rate:.2f})\\\")\\n            return\\n\\n        feature = feature_names[tree.feature[node_index]]\\n        threshold = tree.threshold[node_index]\\n\\n        left_rule = f\\\"{current_rule} AND {feature} <= {threshold:.2f}\\\" if current_rule else f\\\"{feature} <= {threshold:.2f}\\\"\\n        get_rules(tree, feature_names, tree.children_left[node_index], left_rule)\\n\\n        right_rule = f\\\"{current_rule} AND {feature} > {threshold:.2f}\\\" if current_rule else f\\\"{feature} > {threshold:.2f}\\\"\\n        get_rules(tree, feature_names, tree.children_right[node_index], right_rule)\\n\\n    get_rules(dt_analyzer.tree_, feature_names)\\n\\n    if tree_rules:\\n        for rule in tree_rules:\\n            print(f\\\"- {rule}\\\")\\n    else:\\n        print(\\\"No strongly divergent subgroups identified with this simple analysis.\\\")\\n\\ndef interactive_exploration():\\n    print(\\\"\\\\n--- Interactive Explanation Console (E-commerce Customer Churn) ---\\\")\\n    while True:\\n        print(\\\"\\\\nSelect an action:\\\")\\n        print(\\\"1. Get local explanations for a specific customer\\\")\\n        print(\\\"2. Generate a counterfactual explanation (e.g., how to prevent churn)\\\")\\n        print(\\\"3. Perform subgroup divergence analysis\\\")\\n        print(\\\"4. View global surrogate model insights\\\")\\n        print(\\\"5. Exit\\\")\\n\\n        choice = input(\\\"Enter choice (1-5): \\\")\\n\\n        if choice == '1':\\n            try:\\n                idx = int(input(f\\\"Enter test instance index (0 to {len(X_test)-1}): \\\"))\\n                if 0 <= idx < len(X_test):\\n                    explain_instance(idx)\\n                else:\\n                    print(\\\"Invalid index.\\\")\\n            except ValueError:\\n                print(\\\"Invalid input.\\\")\\n        elif choice == '2':\\n            try:\\n                idx = int(input(f\\\"Enter test instance index for counterfactual (0 to {len(X_test)-1}): \\\"))\\n                if 0 <= idx < len(X_test):\\n                    generate_counterfactual(idx)\\n                else:\\n                    print(\\\"Invalid index.\\\")\\n            except ValueError:\\n                print(\\\"Invalid input.\\\")\\n        elif choice == '3':\\n            subgroup_divergence_analysis()\\n        elif choice == '4':\\n            print(\\\"\\\\n--- Global Understanding (Gradient Boosting Surrogate) ---\\\")\\n            print(\\\"Top features for global surrogate (feature importances):\\\")\\n            for f, imp in zip(feature_names, global_surrogate_model.feature_importances_):\\n                print(f\\\"  {f}: {imp:.4f}\\\")\\n        elif choice == '5':\\n            print(\\\"Exiting interactive exploration.\\\")\\n            break\\n        else:\\n            print(\\\"Invalid choice. Please try again.\\\")\\n\\ninteractive_exploration()\"\n",
      "]\n",
      "Generating 3 code examples for the Holistic LLM Agentic Framework pattern...\n",
      "Generating 3 code examples for the Parallel Tool Execution pattern...\n",
      "Generating 3 code examples for the Adversarial Agent Interaction pattern...\n",
      "Generating 3 code examples for the Comprehensive Black-Box Explainability and Analysis Framework pattern...\n",
      "Saved Parallel Tool Execution pattern examples\n",
      "Error decoding JSON for pattern Comprehensive Black-Box Explainability and Analysis Framework: Expecting value: line 1 column 1 (char 0)\n",
      "Output content: json\n",
      "[\n",
      "    \"import numpy as np\\nimport pandas as pd\\nfrom sklearn.model_selection import train_test_split\\nfrom sklearn.ensemble import RandomForestClassifier\\nfrom sklearn.tree import DecisionTreeClassifier, export_text\\nfrom sklearn.metrics import accuracy_score\\nimport shap\\nimport dice_ml\\n\\nnp.random.seed(42)\\nn_samples = 1000\\ndata = {\\n    'age': np.random.randint(20, 70, n_samples),\\n    'income': np.random.randint(30000, 150000, n_samples),\\n    'credit_score': np.random.randint(300, 850, n_samples),\\n    'loan_amount': np.random.randint(5000, 100000, n_samples),\\n    'loan_term': np.random.choice([12, 24, 36, 48, 60], n_samples),\\n    'employment_years': np.random.randint(0, 30, n_samples)\\n}\\ndf = pd.DataFrame(data)\\ndf['debt_to_income'] = df['loan_amount'] / df['income']\\ndf['risk_score'] = (df['loan_amount'] / 10000) - (df['credit_score'] / 100) + (df['debt_to_income'] * 10) - (df['employment_years'] / 5)\\ndf['approved'] = (df['risk_score'] < 5).astype(int)\\n\\nX = df[['age', 'income', 'credit_score', 'loan_amount', 'loan_term', 'employment_years', 'debt_to_income']]\\ny = df['approved']\\nfeature_names = X.columns.tolist()\\n\\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\\n\\nblack_box_model = RandomForestClassifier(n_estimators=100, random_state=42)\\nblack_box_model.fit(X_train, y_train)\\nprint(\\\"Black-box model accuracy:\\\", accuracy_score(y_test, black_box_model.predict(X_test)))\\n\\nsurrogate_model = DecisionTreeClassifier(max_depth=5, random_state=42)\\nsurrogate_model.fit(X_train, black_box_model.predict(X_train))\\nprint(\\\"\\\\nGlobal Surrogate Model (Decision Tree Rules):\\\")\\nprint(export_text(surrogate_model, feature_names=feature_names))\\n\\nexplainer = shap.TreeExplainer(black_box_model)\\nshap_values = explainer.shap_values(X_test)\\nsample_idx = 0\\ninstance_to_explain = X_test.iloc[[sample_idx]]\\nprint(f\\\"\\\\nExplaining prediction for instance {sample_idx} (Loan Approved: {black_box_model.predict(instance_to_explain)[0]}):\\\")\\nshap_object = shap.Explanation(values=shap_values[1][sample_idx], base_values=explainer.expected_value[1], data=instance_to_explain.values[0], feature_names=feature_names)\\nprint(\\\"SHAP values (positive for approval contribution):\\\", dict(zip(feature_names, shap_object.values)))\\n\\nd = dice_ml.Data(dataframe=pd.concat([X, y], axis=1), continuous_features=feature_names, outcome_name='approved')\\nm = dice_ml.Model(model=black_box_model, backend=\\\"sklearn\\\")\\nexp = dice_ml.Dice(d, m, method=\\\"random\\\")\\nquery_instance = X_test.iloc[[sample_idx]]\\nif black_box_model.predict(query_instance)[0] == 0:\\n    cf_explanation = exp.generate_counterfactuals(query_instance, total_CFs=1, desired_class=1)\\n    print(\\\"\\\\nCounterfactual Explanation (How to get approved):\\\")\\n    print(cf_explanation.cf_examples_list[0].final_cfs_df)\\nelse:\\n    cf_explanation = exp.generate_counterfactuals(query_instance, total_CFs=1, desired_class=0)\\n    print(\\\"\\\\nCounterfactual Explanation (How to get rejected):\\\")\\n    print(cf_explanation.cf_examples_list[0].final_cfs_df)\\n\\nlow_credit_subgroup = X_test[X_test['credit_score'] < 600]\\nlow_credit_subgroup_y_true = y_test[X_test['credit_score'] < 600]\\nlow_credit_subgroup_preds = black_box_model.predict(low_credit_subgroup)\\nlow_credit_rejection_rate = 1 - np.mean(low_credit_subgroup_preds)\\noverall_rejection_rate = 1 - np.mean(black_box_model.predict(X_test))\\nprint(f\\\"\\\\nSubgroup Analysis (Low Credit Score < 600):\\\")\\nprint(f\\\"Overall rejection rate: {overall_rejection_rate:.2f}\\\")\\nprint(f\\\"Low credit score subgroup rejection rate: {low_credit_rejection_rate:.2f}\\\")\\nif not low_credit_subgroup.empty:\\n    subgroup_shap_values = explainer.shap_values(low_credit_subgroup)\\n    mean_abs_shap_subgroup = np.abs(subgroup_shap_values[1]).mean(axis=0)\\n    print(\\\"Mean absolute SHAP values for low credit subgroup:\\\", dict(zip(feature_names, mean_abs_shap_subgroup)))\\n\\nprint(\\\"\\\\nInteractive Exploration Summary:\\\")\\nprint(\\\"Global rules provide a high-level overview of approval criteria.\\\")\\nprint(f\\\"For instance {sample_idx}, SHAP values highlight specific factors contributing to the {black_box_model.predict(instance_to_explain)[0]} decision.\\\")\\nprint(\\\"Counterfactuals show actionable changes for desired outcomes.\\\")\\nprint(\\\"Subgroup analysis reveals potential disparities in model behavior for specific groups.\\\")\",\n",
      "    \"import numpy as np\\nimport pandas as pd\\nfrom sklearn.model_selection import train_test_split\\nfrom sklearn.ensemble import GradientBoostingClassifier\\nfrom sklearn.linear_model import LogisticRegression\\nfrom sklearn.metrics import accuracy_score\\nimport lime\\nimport lime.lime_tabular\\nimport dice_ml\\n\\nnp.random.seed(43)\\nn_samples = 1000\\ndata = {\\n    'age': np.random.randint(25, 80, n_samples),\\n    'bmi': np.random.uniform(18, 40, n_samples),\\n    'blood_pressure': np.random.randint(90, 180, n_samples),\\n    'cholesterol': np.random.randint(150, 300, n_samples),\\n    'glucose': np.random.randint(70, 200, n_samples),\\n    'smoking': np.random.choice([0, 1], n_samples, p=[0.7, 0.3]),\\n    'exercise_hours_week': np.random.randint(0, 10, n_samples)\\n}\\ndf = pd.DataFrame(data)\\ndf['risk_factor'] = (df['age'] * 0.05 + df['bmi'] * 0.1 + df['blood_pressure'] * 0.02 +\\n                     df['cholesterol'] * 0.01 + df['glucose'] * 0.03 + df['smoking'] * 2 -\\n                     df['exercise_hours_week'] * 0.5)\\ndf['diagnosis_risk'] = (df['risk_factor'] > np.percentile(df['risk_factor'], 70)).astype(int)\\n\\nX = df[['age', 'bmi', 'blood_pressure', 'cholesterol', 'glucose', 'smoking', 'exercise_hours_week']]\\ny = df['diagnosis_risk']\\nfeature_names = X.columns.tolist()\\n\\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=43)\\n\\nblack_box_model = GradientBoostingClassifier(n_estimators=100, learning_rate=0.1, max_depth=3, random_state=43)\\nblack_box_model.fit(X_train, y_train)\\nprint(\\\"Black-box model accuracy:\\\", accuracy_score(y_test, black_box_model.predict(X_test)))\\n\\nsurrogate_model = LogisticRegression(random_state=43, solver='liblinear')\\nsurrogate_model.fit(X_train, black_box_model.predict(X_train))\\nprint(\\\"\\\\nGlobal Surrogate Model (Logistic Regression Coefficients):\\\")\\nfor feature, coef in zip(feature_names, surrogate_model.coef_[0]):\\n    print(f\\\"  {feature}: {coef:.3f}\\\")\\n\\nexplainer = lime.lime_tabular.LimeTabularExplainer(\\n    training_data=X_train.values,\\n    feature_names=feature_names,\\n    class_names=['Low Risk', 'High Risk'],\\n    mode='classification'\\n)\\nsample_idx = 5\\ninstance_to_explain = X_test.iloc[[sample_idx]]\\nexp = explainer.explain_instance(\\n    data_row=instance_to_explain.values[0],\\n    predict_fn=black_box_model.predict_proba,\\n    num_features=5\\n)\\nprint(f\\\"\\\\nExplaining prediction for instance {sample_idx} (Predicted Risk: {'High Risk' if black_box_model.predict(instance_to_explain)[0] == 1 else 'Low Risk'}):\\\")\\nprint(\\\"LIME Explanation (Feature contributions):\\\")\\nfor feature, weight in exp.as_list():\\n    print(f\\\"  {feature}: {weight:.3f}\\\")\\n\\nprint(\\\"\\\\nLocal Rule-Based Explanation (Inferred from LIME):\\\")\\nif exp.as_list():\\n    top_feature_name, top_feature_weight = exp.as_list()[0]\\n    second_feature_name, second_feature_weight = exp.as_list()[1]\\n    print(f\\\"Example Rule: IF {top_feature_name} {'>' if top_feature_weight > 0 else '<'} {instance_to_explain[top_feature_name].values[0]:.2f} AND {second_feature_name} {'>' if second_feature_weight > 0 else '<'} {instance_to_explain[second_feature_name].values[0]:.2f} THEN Diagnosis Risk is {'High' if black_box_model.predict(instance_to_explain)[0] == 1 else 'Low'}.\\\")\\n\\nd = dice_ml.Data(dataframe=pd.concat([X, y], axis=1), continuous_features=feature_names, outcome_name='diagnosis_risk')\\nm = dice_ml.Model(model=black_box_model, backend=\\\"sklearn\\\")\\nexp_dice = dice_ml.Dice(d, m, method=\\\"random\\\")\\nquery_instance = X_test.iloc[[sample_idx]]\\nif black_box_model.predict(query_instance)[0] == 1:\\n    cf_explanation = exp_dice.generate_counterfactuals(query_instance, total_CFs=1, desired_class=0)\\n    print(\\\"\\\\nCounterfactual Explanation (How to reduce risk):\\\")\\n    print(cf_explanation.cf_examples_list[0].final_cfs_df)\\nelse:\\n    cf_explanation = exp_dice.generate_counterfactuals(query_instance, total_CFs=1, desired_class=1)\\n    print(\\\"\\\\nCounterfactual Explanation (How to increase risk):\\\")\\n    print(cf_explanation.cf_examples_list[0].final_cfs_df)\\n\\nelderly_subgroup = X_test[X_test['age'] >= 65]\\nelderly_subgroup_y_true = y_test[X_test['age'] >= 65]\\nelderly_subgroup_preds = black_box_model.predict(elderly_subgroup)\\nelderly_high_risk_rate = np.mean(elderly_subgroup_preds)\\noverall_high_risk_rate = np.mean(black_box_model.predict(X_test))\\nprint(f\\\"\\\\nSubgroup Analysis (Elderly Patients Age >= 65):\\\")\\nprint(f\\\"Overall high risk rate: {overall_high_risk_rate:.2f}\\\")\\nprint(f\\\"Elderly subgroup high risk rate: {elderly_high_risk_rate:.2f}\\\")\\nif not elderly_subgroup.empty:\\n    typical_elderly_instance = elderly_subgroup.iloc[[0]]\\n    exp_elderly = explainer.explain_instance(\\n        data_row=typical_elderly_instance.values[0],\\n        predict_fn=black_box_model.predict_proba,\\n        num_features=5\\n    )\\n    print(f\\\"LIME explanation for a typical elderly patient (instance {elderly_subgroup.index[0]}):\\\")\\n    for feature, weight in exp_elderly.as_list():\\n        print(f\\\"  {feature}: {weight:.3f}\\\")\\n\\nprint(\\\"\\\\nInteractive Exploration Summary:\\\")\\nprint(\\\"Global model coefficients show general risk factors.\\\")\\nprint(f\\\"For patient {sample_idx}, LIME highlights specific health metrics contributing to their risk.\\\")\\nprint(\\\"Counterfactuals offer concrete steps to modify risk.\\\")\\nprint(\\\"Subgroup analysis reveals the model's differing behavior or reliance on features for elderly patients.\\\")\",\n",
      "    \"import numpy as np\\nimport pandas as pd\\nfrom sklearn.model_selection import train_test_split\\nimport xgboost as xgb\\nfrom sklearn.neighbors import KNeighborsClassifier\\nfrom sklearn.metrics import accuracy_score\\nimport shap\\nimport dice_ml\\n\\nnp.random.seed(44)\\nn_samples = 1000\\ndata = {\\n    'user_age': np.random.randint(18, 65, n_samples),\\n    'user_income': np.random.randint(20000, 120000, n_samples),\\n    'product_price': np.random.uniform(10, 500, n_samples),\\n    'product_category_fashion': np.random.choice([0, 1], n_samples, p=[0.6, 0.4]),\\n    'product_category_electronics': np.random.choice([0, 1], n_samples, p=[0.7, 0.3]),\\n    'user_interaction_score': np.random.uniform(0.1, 10.0, n_samples),\\n    'user_purchase_history_value': np.random.randint(0, 5000, n_samples)\\n}\\ndf = pd.DataFrame(data)\\ndf['recommendation_score'] = (df['user_interaction_score'] * 2 +\\n                              df['user_purchase_history_value'] * 0.01 -\\n                              df['product_price'] * 0.05 +\\n                              df['user_income'] * 0.00005 +\\n                              df['product_category_fashion'] * 1.5 +\\n                              df['product_category_electronics'] * 1.0)\\ndf['recommended'] = (df['recommendation_score'] > np.percentile(df['recommendation_score'], 50)).astype(int)\\n\\nX = df[['user_age', 'user_income', 'product_price', 'product_category_fashion',\\n        'product_category_electronics', 'user_interaction_score', 'user_purchase_history_value']]\\ny = df['recommended']\\nfeature_names = X.columns.tolist()\\n\\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=44)\\n\\nblack_box_model = xgb.XGBClassifier(n_estimators=100, use_label_encoder=False, eval_metric='logloss', random_state=44)\\nblack_box_model.fit(X_train, y_train)\\nprint(\\\"Black-box model accuracy:\\\", accuracy_score(y_test, black_box_model.predict(X_test)))\\n\\nsurrogate_model = KNeighborsClassifier(n_neighbors=5)\\nsurrogate_model.fit(X_train, black_box_model.predict(X_train))\\nprint(\\\"\\\\nGlobal Surrogate Model (K-Nearest Neighbors - conceptual understanding):\\\")\\nprint(\\\"KNN identifies recommendations based on similarity to past user-product interactions.\\\")\\nprint(\\\"This suggests that similar users interacting with similar products will receive similar recommendations.\\\")\\n\\nexplainer = shap.TreeExplainer(black_box_model)\\nshap_values = explainer.shap_values(X_test)\\nsample_idx = 10\\ninstance_to_explain = X_test.iloc[[sample_idx]]\\nprint(f\\\"\\\\nExplaining prediction for instance {sample_idx} (Product Recommended: {black_box_model.predict(instance_to_explain)[0]}):\\\")\\nshap_object = shap.Explanation(values=shap_values[1][sample_idx], base_values=explainer.expected_value[1], data=instance_to_explain.values[0], feature_names=feature_names)\\nprint(\\\"SHAP values (positive for recommendation contribution):\\\", dict(zip(feature_names, shap_object.values)))\\n\\nd = dice_ml.Data(dataframe=pd.concat([X, y], axis=1), continuous_features=feature_names, outcome_name='recommended')\\nm = dice_ml.Model(model=black_box_model, backend=\\\"sklearn\\\")\\nexp_dice = dice_ml.Dice(d, m, method=\\\"random\\\")\\nquery_instance = X_test.iloc[[sample_idx]]\\nif black_box_model.predict(query_instance)[0] == 0:\\n    cf_explanation = exp_dice.generate_counterfactuals(query_instance, total_CFs=1, desired_class=1)\\n    print(\\\"\\\\nCounterfactual Explanation (How to get recommended):\\\")\\n    print(cf_explanation.cf_examples_list[0].final_cfs_df)\\nelse:\\n    cf_explanation = exp_dice.generate_counterfactuals(query_instance, total_CFs=1, desired_class=0)\\n    print(\\\"\\\\nCounterfactual Explanation (How to not get recommended):\\\")\\n    print(cf_explanation.cf_examples_list[0].final_cfs_df)\\n\\nhigh_income_subgroup = X_test[X_test['user_income'] >= 80000]\\nhigh_income_subgroup_y_true = y_test[X_test['user_income'] >= 80000]\\nhigh_income_subgroup_preds = black_box_model.predict(high_income_subgroup)\\nhigh_income_recommendation_rate = np.mean(high_income_subgroup_preds)\\noverall_recommendation_rate = np.mean(black_box_model.predict(X_test))\\nprint(f\\\"\\\\nSubgroup Analysis (High Income Users >= $80,000):\\\")\\nprint(f\\\"Overall recommendation rate: {overall_recommendation_rate:.2f}\\\")\\nprint(f\\\"High income subgroup recommendation rate: {high_income_recommendation_rate:.2f}\\\")\\nif not high_income_subgroup.empty:\\n    subgroup_shap_values = explainer.shap_values(high_income_subgroup)\\n    mean_abs_shap_subgroup = np.abs(subgroup_shap_values[1]).mean(axis=0)\\n    print(\\\"Mean absolute SHAP values for high income subgroup:\\\", dict(zip(feature_names, mean_abs_shap_subgroup)))\\n\\nprint(\\\"\\\\nInteractive Exploration: 'What-if' Analysis for Recommendation\\\")\\noriginal_instance = X_test.iloc[[sample_idx]]\\nprint(f\\\"Original instance: {original_instance.to_dict('records')[0]}\\\")\\nprint(f\\\"Original prediction: {'Recommended' if black_box_model.predict(original_instance)[0] == 1 else 'Not Recommended'}\\\")\\nmodified_instance = original_instance.copy()\\nmodified_instance['user_interaction_score'] *= 1.5\\nprint(f\\\"\\\\nModified instance (user_interaction_score * 1.5): {modified_instance.to_dict('records')[0]}\\\")\\nprint(f\\\"New prediction: {'Recommended' if black_box_model.predict(modified_instance)[0] == 1 else 'Not Recommended'}\\\")\"\n",
      "]\n",
      "Saved Holistic LLM Agentic Framework pattern examples\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception in thread Thread-166 (<lambda>):\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/lib/python3.12/threading.py\", line 1073, in _bootstrap_inner\n",
      "    self.run()\n",
      "  File \"/home/hasinthaka/Documents/Projects/AI/AI Pattern Mining/Pattern Validator/.venv/lib/python3.12/site-packages/ipykernel/ipkernel.py\", line 772, in run_closure\n",
      "    _threading_Thread_run(self)\n",
      "  File \"/usr/lib/python3.12/threading.py\", line 1010, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/tmp/ipykernel_82424/766922830.py\", line 9, in <lambda>\n",
      "  File \"/tmp/ipykernel_82424/1972671573.py\", line 15, in save_code\n",
      "  File \"/tmp/ipykernel_82424/1972671573.py\", line 2, in remove_backticks\n",
      "AttributeError: 'list' object has no attribute 'strip'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating 3 code examples for the Holistic LLM Agentic Framework pattern...\n",
      "Generating 3 code examples for the Parallel Tool Execution pattern...\n",
      "Generating 3 code examples for the Adversarial Agent Interaction pattern...\n",
      "Generating 3 code examples for the Comprehensive Black-Box Explainability and Analysis Framework pattern...\n",
      "Saved Holistic LLM Agentic Framework pattern examples\n",
      "Saved Parallel Tool Execution pattern examples\n",
      "Saved Comprehensive Black-Box Explainability and Analysis Framework pattern examples\n",
      "Error decoding JSON for pattern Adversarial Agent Interaction: Expecting value: line 1 column 1 (char 0)\n",
      "Output content: , bad, bad, bad, bad, bad, bad, bad, bad, bad, bad, bad, bad, bad, bad, bad, bad, bad, bad, bad, bad, bad, bad, bad, bad, bad, bad, bad, bad, bad, bad, bad, bad, bad, bad, bad, bad, bad, bad, bad, bad, bad, bad, bad, bad, bad, bad, bad, bad, bad, bad, bad, bad, bad, bad, bad, bad, bad, bad, bad, bad, bad, bad, bad, bad, bad, bad, bad, bad, bad, bad, bad, bad, bad, bad, bad, bad, bad, bad, bad, bad, bad, bad, bad, bad, bad, bad, bad, bad, bad, bad, bad, bad, bad, bad, bad, bad, bad, bad, bad, bad, bad, bad, bad, bad, bad, bad, bad, bad, bad, bad, bad, bad, bad, bad, bad, bad, bad, bad, bad, bad, bad, bad, bad, bad, bad, bad, bad, bad, bad, bad, bad, bad, bad, bad, bad, bad, bad, bad, bad, bad, bad, bad, bad, bad, bad, bad, bad, bad, bad, bad, bad, bad, bad, bad, bad, bad, bad, bad, bad, bad, bad, bad, bad, bad, bad, bad, bad, bad, bad, bad, bad, bad, bad, bad, bad, bad, bad, bad, bad, bad, bad, bad, bad, bad, bad, bad, bad, bad, bad, bad, bad, bad, bad, bad, bad, bad, bad, bad, bad, bad, bad, bad, bad, bad, bad, bad, bad, bad, bad, bad, bad, bad, bad, bad, bad, bad, bad, bad, bad, bad, bad, bad, bad, bad, bad, bad, bad, bad, bad, bad, bad, bad, bad, bad, bad, bad, bad, bad, bad, bad, bad, bad, bad, bad, bad, bad, bad, bad, bad, bad, bad, bad, bad, bad, bad, bad, bad, bad, bad, bad, bad, bad, bad, bad, bad, bad, bad, bad, bad, bad, bad, bad, bad, bad, bad, bad, bad, bad, bad, bad, bad, bad, bad, bad, bad, bad, bad, bad, bad, bad, bad, bad, bad, bad, bad, bad, bad, bad, bad, bad, bad, bad, bad, bad, bad, bad, bad, bad, bad, bad, bad, bad, bad, bad, bad, bad, bad, bad, bad, bad, bad, bad, bad, bad, bad, bad, bad, bad, bad, bad, bad, bad, bad, bad, bad, bad, bad, bad, bad, bad, bad, bad, bad, bad, bad, bad, bad, bad, bad, bad, bad, bad, bad, bad, bad, bad, bad, bad, bad, bad, bad, bad, bad, bad, bad, bad, bad, bad, bad, bad, bad, bad, bad, bad, bad, bad, bad, bad, bad, bad, bad, bad, bad, bad, bad, bad, bad, bad, bad, bad, bad, bad, bad, bad, bad, bad, bad, bad, bad, bad, bad, bad, bad, bad, bad, bad, bad, bad, bad, bad, bad, bad, bad, bad, bad, bad, bad, bad, bad, bad, bad, bad, bad, bad, bad, bad, bad, bad, bad, bad, bad, bad, bad, bad, bad, bad, bad, bad, bad, bad, bad, bad, bad, bad, bad, bad, bad, bad, bad, bad, bad, bad, bad, bad, bad, bad, bad, bad, bad, bad, bad, bad, bad, bad, bad, bad, bad, bad, bad, bad, bad, bad, bad, bad, bad, bad, bad, bad, bad, bad, bad, bad, bad, bad, bad, bad, bad, bad, bad, bad, bad, bad, bad, bad, bad, bad, bad, bad, bad, bad, bad, bad, bad, bad, bad, bad, bad, bad, bad, bad, bad, bad, bad, bad, bad, bad, bad, bad, bad, bad, bad, bad, bad, bad, bad, bad, bad, bad, bad, bad, bad, bad, bad, bad, bad, bad, bad, bad, bad, bad, bad, bad, bad, bad, bad, bad, bad, bad, bad, bad, bad, bad, bad, bad, bad, bad, bad, bad, bad, bad, bad, bad, bad, bad, bad, bad, bad, bad, bad, bad, bad, bad, bad, bad, bad, bad, bad, bad, bad, bad, bad, bad, bad, bad, bad, bad, bad, bad, bad, bad, bad, bad, bad, bad, bad, bad, bad, bad, bad, bad, bad, bad, bad, bad, bad, bad, bad, bad, bad, bad, bad, bad, bad, bad, bad, bad, bad, bad, bad, bad, bad, bad, bad, bad, bad, bad, bad, bad, bad, bad, bad, bad, bad, bad, bad, bad, bad, bad, bad, bad, bad, bad, bad, bad, bad, bad, bad, bad, bad, bad, bad, bad, bad, bad, bad, bad, bad, bad, bad, bad, bad, bad, bad, bad, bad, bad, bad, bad, bad, bad, bad, bad, bad, bad, bad, bad, bad, bad, bad, bad, bad, bad, bad, bad, bad, bad, bad, bad, bad, bad, bad, bad, bad, bad, bad, bad, bad, bad, bad, bad, bad, bad, bad, bad, bad, bad, bad, bad, bad, bad, bad, bad, bad, bad, bad, bad, bad, bad, bad, bad, bad, bad, bad, bad, bad, bad, bad, bad, bad, bad, bad, bad, bad, bad, bad, bad, bad, bad, bad, bad, bad, bad, bad, bad, bad, bad, bad, bad, bad, bad, bad, bad, bad, bad, bad, bad, bad, bad, bad, bad, bad, bad, bad, bad, bad, bad, bad, bad, bad, bad, bad, bad, bad, bad, bad, bad, bad, bad, bad, bad, bad, bad, bad, bad, bad, bad, bad, bad, bad, bad, bad, bad, bad, bad, bad, bad, bad, bad, bad, bad, bad, bad, bad, bad, bad, bad, bad, bad, bad, bad, bad, bad, bad, bad, bad, bad, bad, bad, bad, bad, bad, bad, bad, bad, bad, bad, bad, bad, bad, bad, bad, bad, bad, bad, bad, bad, bad, bad, bad, bad, bad, bad, bad, bad, bad, bad, bad, bad, bad, bad, bad, bad, bad, bad, bad, bad, bad, bad, bad, bad, bad, bad, bad, bad, bad, bad, bad, bad, bad, bad, bad, bad, bad, bad, bad, bad, bad, bad, bad, bad, bad, bad, bad, bad, bad, bad, bad, bad, bad, bad, bad, bad, bad, bad, bad, bad, bad, bad, bad, bad, bad, bad, bad, bad, bad, bad, bad, bad, bad, bad, bad, bad, bad, bad, bad, bad, bad, bad, bad, bad, bad, bad, bad, bad, bad, bad, bad, bad, bad, bad, bad, bad, bad, bad, bad, bad, bad, bad, bad, bad, bad, bad, bad, bad, bad, bad, bad, bad, bad, bad, bad, bad, bad, bad, bad, bad, bad, bad, bad, bad, bad, bad, bad, bad, bad, bad, bad, bad, bad, bad, bad, bad, bad, bad, bad, bad, bad, bad, bad, bad, bad, bad, bad, bad, bad, bad, bad, bad, bad, bad, bad, bad, bad, bad, bad, bad, bad, bad, bad, bad, bad, bad, bad, bad, bad, bad, bad, bad, bad, bad, bad, bad, bad, bad, bad, bad, bad, bad, bad, bad, bad, bad, bad, bad, bad, bad, bad, bad, bad, bad, bad, bad, bad, bad, bad, bad, bad, bad, bad, bad, bad, bad, bad, bad, bad, bad, bad, bad, bad, bad, bad, bad, bad, bad, bad, bad, bad, bad, bad, bad, bad, bad, bad, bad, bad, bad, bad, bad, bad, bad, bad, bad, bad, bad, bad, bad, bad, bad, bad, bad, bad, bad, bad, bad, bad, bad, bad, bad, bad, bad, bad, bad, bad, bad, bad, bad, bad, bad, bad, bad, bad, bad, bad, bad, bad, bad, bad, bad, bad, bad, bad, bad, bad, bad, bad, bad, bad, bad, bad, bad, bad, bad, bad, bad, bad, bad, bad, bad, bad, bad, bad, bad, bad, bad, bad, bad, bad, bad, bad, bad, bad, bad, bad, bad, bad, bad, bad, bad, bad, bad, bad, bad, bad, bad, bad, bad, bad, bad, bad, bad, bad, bad, bad, bad, bad, bad, bad, bad, bad, bad, bad, bad, bad, bad, bad, bad, bad, bad, bad, bad, bad, bad, bad, bad, bad, bad, bad, bad, bad, bad, bad, bad, bad, bad, bad, bad, bad, bad, bad, bad, bad, bad, bad, bad, bad, bad, bad, bad, bad, bad, bad, bad, bad, bad, bad, bad, bad, bad, bad, bad, bad, bad, bad, bad, bad, bad, bad, bad, bad, bad, bad, bad, bad, bad, bad, bad, bad, bad, bad, bad, bad, bad, bad, bad, bad, bad, bad, bad, bad, bad, bad, bad, bad, bad, bad, bad, bad, bad, bad, bad, bad, bad, bad, bad, bad, bad, bad, bad, bad, bad, bad, bad, bad, bad, bad, bad, bad, bad, bad, bad, bad, bad, bad, bad, bad, bad, bad, bad, bad, bad, bad, bad, bad, bad, bad, bad, bad, bad, bad, bad, bad, bad, bad, bad, bad, bad, bad, bad, bad,\n",
      "Generating 3 code examples for the Holistic LLM Agentic Framework pattern...\n",
      "Generating 3 code examples for the Parallel Tool Execution pattern...\n",
      "Generating 3 code examples for the Adversarial Agent Interaction pattern...\n",
      "Generating 3 code examples for the Comprehensive Black-Box Explainability and Analysis Framework pattern...\n",
      "Saved Parallel Tool Execution pattern examples\n",
      "Error decoding JSON for pattern Holistic LLM Agentic Framework: Expecting ',' delimiter: line 4 column 4387 (char 31123)\n",
      "Output content: [\n",
      "  \"import abc\\n\\nclass LLMAdapter:\\n    def __init__(self, model_name=\\\"Simulated_LLM\\\"):\\n        self.model_name = model_name\\n\\n    def understand_intent(self, query):\\n        print(f\\\"[{self.model_name}] Understanding intent for: '{query}'\\\")\\n        if \\\"symptoms\\\" in query.lower() or \\\"feel sick\\\" in query.lower():\\n            return \\\"DIAGNOSIS_REQUEST\\\"\\n        if \\\"medication\\\" in query.lower() or \\\"drug\\\" in query.lower():\\n            return \\\"MEDICATION_QUERY\\\"\\n        return \\\"GENERAL_QUERY\\\"\\n\\n    def reason_diagnosis(self, symptoms, patient_history, medical_knowledge):\\n        print(f\\\"[{self.model_name}] Reasoning diagnosis for symptoms: {symptoms}\\\")\\n        print(f\\\"  Considering patient history: {patient_history}\\\")\\n        print(f\\\"  Consulting medical knowledge: {medical_knowledge[:50]}...\\\")\\n        if \\\"fever\\\" in symptoms and \\\"cough\\\" in symptoms and \\\"fatigue\\\" in symptoms:\\n            return [\\\"Flu\\\", \\\"Common Cold\\\", \\\"Bronchitis\\\"]\\n        if \\\"chest pain\\\" in symptoms and \\\"shortness of breath\\\" in symptoms:\\n            return [\\\"Angina\\\", \\\"Anxiety Attack\\\", \\\"Pneumonia\\\"]\\n        return [\\\"Uncertain Condition\\\"]\\n\\n    def generate_report(self, diagnosis_results, actions_taken):\\n        report = f\\\"\\\\n--- Diagnostic Report ---\\\\n\\\"\\n        report += f\\\"Based on analysis, potential diagnoses: {', '.join(diagnosis_results)}\\\\n\\\"\\n        report += f\\\"Actions taken: {', '.join(actions_taken)}\\\\n\\\"\\n        report += \\\"Recommendation: Consult with a physician for definitive diagnosis and treatment plan.\\\\n\\\"\\n        report += \\\"-----------------------\\\"\\n        return report\\n\\nclass MemorySystem:\\n    def __init__(self):\\n        self.working_memory = {}\\n        self.episodic_memory = [] # Patient visit history\\n        self.semantic_memory = {\\n            \\\"Flu\\\": {\\\"symptoms\\\": [\\\"fever\\\", \\\"cough\\\", \\\"fatigue\\\"], \\\"treatment\\\": \\\"rest, fluids\\\"},\\n            \\\"Common Cold\\\": {\\\"symptoms\\\": [\\\"cough\\\", \\\"sore throat\\\"], \\\"treatment\\\": \\\"rest\\\"},\\n            \\\"Angina\\\": {\\\"symptoms\\\": [\\\"chest pain\\\"], \\\"treatment\\\": \\\"medication\\\"}\\n        }\\n        self.procedural_memory = {\\n            \\\"DIAGNOSIS_PROTOCOL\\\": [\\\"gather_symptoms\\\", \\\"check_history\\\", \\\"consult_knowledge\\\", \\\"propose_diagnosis\\\", \\\"order_tests\\\"],\\n            \\\"DRUG_INTERACTION_CHECK\\\": [\\\"input_drugs\\\", \\\"query_database\\\", \\\"report_interactions\\\"]\\n        }\\n\\n    def add_to_working_memory(self, key, value):\\n        self.working_memory[key] = value\\n\\n    def get_from_working_memory(self, key):\\n        return self.working_memory.get(key)\\n\\n    def add_episodic_memory(self, event):\\n        self.episodic_memory.append(event)\\n\\n    def get_patient_history(self, patient_id):\\n        return [e for e in self.episodic_memory if e.get('patient_id') == patient_id]\\n\\nclass KnowledgeBase:\\n    def __init__(self):\\n        self.medical_articles = {\\n            \\\"fever\\\": \\\"Fever is an increase in body temperature...\\\",\\n            \\\"cough\\\": \\\"A cough is a reflex action...\\\",\\n            \\\"drug_interactions\\\": \\\"Database of drug interaction warnings...\\\"\\n        }\\n\\n    def retrieve(self, query_keywords):\\n        retrieved_info = []\\n        for keyword in query_keywords:\\n            if keyword.lower() in self.medical_articles:\\n                retrieved_info.append(self.medical_articles[keyword.lower()])\\n        return \\\" \\\".join(retrieved_info) if retrieved_info else \\\"No specific articles found.\\\"\\n\\nclass Tool(abc.ABC):\\n    @abc.abstractmethod\\n    def name(self):\\n        pass\\n\\n    @abc.abstractmethod\\n    def execute(self, *args, **kwargs):\\n        pass\\n\\nclass SymptomCheckerTool(Tool):\\n    def name(self):\\n        return \\\"SymptomCheckerTool\\\"\\n\\n    def execute(self, symptoms):\\n        print(f\\\"[Tool:SymptomChecker] Checking common conditions for symptoms: {symptoms}\\\")\\n        if \\\"fever\\\" in symptoms and \\\"cough\\\" in symptoms:\\n            return {\\\"suggested_conditions\\\": [\\\"Flu\\\", \\\"Common Cold\\\"], \\\"confidence\\\": 0.7}\\n        return {\\\"suggested_conditions\\\": [], \\\"confidence\\\": 0.0}\\n\\nclass LabOrderTool(Tool):\\n    def name(self):\\n        return \\\"LabOrderTool\\\"\\n\\n    def execute(self, patient_id, tests):\\n        print(f\\\"[Tool:LabOrder] Ordering {', '.join(tests)} for patient {patient_id}\\\")\\n        # Simulate lab order placement and result waiting\\n        return {\\\"status\\\": \\\"ordered\\\", \\\"results_expected_in_days\\\": 2}\\n\\nclass DrugInteractionTool(Tool):\\n    def name(self):\\n        return \\\"DrugInteractionTool\\\"\\n\\n    def execute(self, drugs):\\n        print(f\\\"[Tool:DrugInteraction] Checking interactions for drugs: {drugs}\\\")\\n        if \\\"Warfarin\\\" in drugs and \\\"Aspirin\\\" in drugs:\\n            return {\\\"interaction_found\\\": True, \\\"warning\\\": \\\"High risk of bleeding\\\"}\\n        return {\\\"interaction_found\\\": False, \\\"warning\\\": \\\"None\\\"}\\n\\nclass DiagnosticAgent:\\n    def __init__(self, patient_id):\\n        self.patient_id = patient_id\\n        self.llm = LLMAdapter()\\n        self.memory = MemorySystem()\\n        self.knowledge_base = KnowledgeBase()\\n        self.tools = {\\n            \\\"symptom_checker\\\": SymptomCheckerTool(),\\n            \\\"lab_order\\\": LabOrderTool(),\\n            \\\"drug_interaction\\\": DrugInteractionTool()\\n        }\\n        self.actions_taken = []\\n\\n    def _plan_and_execute(self, intent, symptoms=None, drugs=None):\\n        plan = []\\n        if intent == \\\"DIAGNOSIS_REQUEST\\\" and symptoms:\\n            plan = self.memory.procedural_memory[\\\"DIAGNOSIS_PROTOCOL\\\"]\\n            self.memory.add_to_working_memory(\\\"current_symptoms\\\", symptoms)\\n        elif intent == \\\"MEDICATION_QUERY\\\" and drugs:\\n            plan = self.memory.procedural_memory[\\\"DRUG_INTERACTION_CHECK\\\"]\\n            self.memory.add_to_working_memory(\\\"current_drugs\\\", drugs)\\n        else:\\n            print(\\\"[Agent] No specific plan for this intent.\\\")\\n            return []\\n\\n        print(f\\\"[Agent] Executing plan: {plan}\\\")\\n        results = []\\n        for step in plan:\\n            if step == \\\"gather_symptoms\\\":\\n                # Symptoms already provided as input\\n                pass\\n            elif step == \\\"check_history\\\":\\n                history = self.memory.get_patient_history(self.patient_id)\\n                self.memory.add_to_working_memory(\\\"patient_history\\\", history)\\n                self.actions_taken.append(\\\"Checked patient history\\\")\\n            elif step == \\\"consult_knowledge\\\":\\n                medical_info = self.knowledge_base.retrieve(symptoms)\\n                self.memory.add_to_working_memory(\\\"medical_info\\\", medical_info)\\n                self.actions_taken.append(\\\"Consulted medical knowledge base\\\")\\n            elif step == \\\"propose_diagnosis\\\":\\n                current_symptoms = self.memory.get_from_working_memory(\\\"current_symptoms\\\")\\n                patient_history = self.memory.get_from_working_memory(\\\"patient_history\\\")\\n                medical_info = self.memory.get_from_working_memory(\\\"medical_info\\\")\\n                diagnoses = self.llm.reason_diagnosis(current_symptoms, patient_history, medical_info)\\n                self.memory.add_to_working_memory(\\\"proposed_diagnoses\\\", diagnoses)\\n                self.actions_taken.append(f\\\"Proposed diagnoses: {', '.join(diagnoses)}\\\")\\n                results.extend(diagnoses)\\n            elif step == \\\"order_tests\\\":\\n                if \\\"proposed_diagnoses\\\" in self.memory.working_memory and \\\"Angina\\\" in self.memory.working_memory[\\\"proposed_diagnoses\\\"]:\\n                    lab_result = self.tools[\\\"lab_order\\\"].execute(self.patient_id, [\\\"ECG\\\", \\\"Blood Panel\\\"])\\n                    self.actions_taken.append(f\\\"Ordered lab tests: ECG, Blood Panel (Status: {lab_result['status']})\\\")\\n            elif step == \\\"input_drugs\\\":\\n                # Drugs already provided as input\\n                pass\\n            elif step == \\\"query_database\\\":\\n                drug_interaction_result = self.tools[\\\"drug_interaction\\\"].execute(drugs)\\n                self.actions_taken.append(f\\\"Checked drug interactions for {drugs}: {drug_interaction_result['warning']}\\\")\\n                results.append(drug_interaction_result)\\n            else:\\n                print(f\\\"[Agent] Unknown plan step: {step}\\\")\\n        return results\\n\\n    def verify_facts(self, diagnosis, symptoms):\\n        print(f\\\"[Agent] Verifying diagnosis '{diagnosis}' against symptoms '{symptoms}'\\\")\\n        semantic_data = self.memory.semantic_memory.get(diagnosis, {})\\n        required_symptoms = semantic_data.get(\\\"symptoms\\\", [])\\n        missing_symptoms = [s for s in required_symptoms if s not in symptoms]\\n        if missing_symptoms:\\n            print(f\\\"[Agent] Warning: Symptoms '{', '.join(missing_symptoms)}' expected for '{diagnosis}' are missing.\\\")\\n            return False\\n        return True\\n\\n    def learn_from_experience(self, case_summary):\\n        self.memory.add_episodic_memory(case_summary)\\n        print(f\\\"[Agent] Learning: Case summary added to episodic memory for patient {self.patient_id}.\\\")\\n\\n    def process_query(self, query, patient_symptoms=None, patient_drugs=None):\\n        intent = self.llm.understand_intent(query)\\n        self.actions_taken = []\\n\\n        if intent == \\\"DIAGNOSIS_REQUEST\\\" and patient_symptoms:\\n            print(f\\\"[Agent] Processing diagnosis request for patient {self.patient_id} with symptoms: {patient_symptoms}\\\")\\n            self.memory.add_episodic_memory({\\\"patient_id\\\": self.patient_id, \\\"type\\\": \\\"symptoms_reported\\\", \\\"symptoms\\\": patient_symptoms})\\n\\n            diagnoses = self._plan_and_execute(intent, symptoms=patient_symptoms)\\n            verified_diagnoses = [d for d in diagnoses if self.verify_facts(d, patient_symptoms)]\\n\\n            report = self.llm.generate_report(verified_diagnoses if verified_diagnoses else diagnoses, self.actions_taken)\\n            self.learn_from_experience({\\\"patient_id\\\": self.patient_id, \\\"query\\\": query, \\\"diagnoses\\\": verified_diagnoses,\\n                                         \\\"actions\\\": self.actions_taken, \\\"outcome\\\": \\\"report_generated\\\"})\\n            print(report)\\n\\n        elif intent == \\\"MEDICATION_QUERY\\\" and patient_drugs:\\n            print(f\\\"[Agent] Processing medication query for patient {self.patient_id} with drugs: {patient_drugs}\\\")\\n            self.memory.add_episodic_memory({\\\"patient_id\\\": self.patient_id, \\\"type\\\": \\\"medication_query\\\", \\\"drugs\\\": patient_drugs})\\n\\n            interaction_results = self._plan_and_execute(intent, drugs=patient_drugs)\\n            report = f\\\"\\\\n--- Medication Interaction Report ---\\\\n\\\"\\n            for res in interaction_results:\\n                if res.get('interaction_found'):\\n                    report += f\\\"WARNING: {res['warning']}\\\\n\\\"\\n                else:\\n                    report += f\\\"No significant interactions found.\\\\n\\\"\\n            report += f\\\"Actions taken: {', '.join(self.actions_taken)}\\\\n\\\"\\n            report += \\\"-------------------------------------\\\"\\n            self.learn_from_experience({\\\"patient_id\\\": self.patient_id, \\\"query\\\": query, \\\"drugs\\\": patient_drugs,\\n                                         \\\"actions\\\": self.actions_taken, \\\"outcome\\\": \\\"interaction_report_generated\\\"})\\n            print(report)\\n\\n        else:\\n            print(\\\"[Agent] Could not process query effectively. Please provide more details.\\\")\\n\\n# Real-world Usage & Simulation Pattern\\n\\n# Scenario 1: Patient with flu-like symptoms\\nprint(\\\"\\\\n--- Simulation 1: Patient with Flu-like Symptoms ---\\\")\\npatient1_agent = DiagnosticAgent(patient_id=\\\"P001\\\")\\npatient1_agent.process_query(\\\"I'm feeling sick, have a fever and cough.\\\", patient_symptoms=[\\\"fever\\\", \\\"cough\\\", \\\"fatigue\\\"])\\n\\nprint(\\\"\\\\n--- Simulation 2: Patient with Chest Pain ---\\\")\\npatient2_agent = DiagnosticAgent(patient_id=\\\"P002\\\")\\npatient2_agent.process_query(\\\"I have chest pain and shortness of breath.\\\", patient_symptoms=[\\\"chest pain\\\", \\\"shortness of breath\\\"])\\n\\nprint(\\\"\\\\n--- Simulation 3: Medication Interaction Check ---\\\")\\npatient3_agent = DiagnosticAgent(patient_id=\\\"P003\\\")\\npatient3_agent.process_query(\\\"Are Warfarin and Aspirin safe to take together?\\\", patient_drugs=[\\\"Warfarin\\\", \\\"Aspirin\\\"])\\n\\nprint(\\\"\\\\n--- Simulation 4: Learning from experience ---\\\")\\nprint(f\\\"Episodic memory for P001: {patient1_agent.memory.get_patient_history('P001')}\\\")\\n\",\n",
      "  \"import abc\\n\\nclass LLMAdapter:\\n    def __init__(self, model_name=\\\"Simulated_LLM\\\"):\\n        self.model_name = model_name\\n\\n    def understand_intent(self, query):\\n        print(f\\\"[{self.model_name}] Understanding intent for: '{query}'\\\")\\n        if \\\"recommend\\\" in query.lower() or \\\"looking for\\\" in query.lower():\\n            return \\\"PRODUCT_RECOMMENDATION\\\"\\n        if \\\"search\\\" in query.lower() or \\\"find\\\" in query.lower():\\n            return \\\"PRODUCT_SEARCH\\\"\\n        if \\\"add to cart\\\" in query.lower() or \\\"buy\\\" in query.lower():\\n            return \\\"PURCHASE_INTENT\\\"\\n        return \\\"GENERAL_QUERY\\\"\\n\\n    def reason_recommendations(self, user_preferences, search_results, product_catalog_info):\\n        print(f\\\"[{self.model_name}] Reasoning recommendations based on preferences: {user_preferences}, search: {search_results[:50]}...\\\")\\n        if \\\"electronics\\\" in user_preferences and \\\"laptop\\\" in search_results:\\n            return [\\\"Dell XPS 15\\\", \\\"MacBook Pro\\\", \\\"HP Spectre x360\\\"]\\n        if \\\"clothing\\\" in user_preferences and \\\"dress\\\" in search_results:\\n            return [\\\"Summer Floral Dress\\\", \\\"Evening Gown\\\"]\\n        return [\\\"Generic Item A\\\", \\\"Generic Item B\\\"]\\n\\n    def generate_response(self, context, action_results):\\n        response = f\\\"\\\\n-- Shopping Assistant Response --\\\\n\\\"\\n        response += f\\\"Context: {context}\\\\n\\\"\\n        response += f\\\"Action Results: {action_results}\\\\n\\\"\\n        response += \\\"How else can I assist you today?\\\\n\\\"\\n        response += \\\"--------------------------------\\\\n\\\"\\n        return response\\n\\nclass MemorySystem:\\n    def __init__(self, user_id):\\n        self.user_id = user_id\\n        self.working_memory = {}\\n        self.episodic_memory = [] # Past purchases, browsing history\\n        self.semantic_memory = {\\n            \\\"electronics\\\": {\\\"keywords\\\": [\\\"laptop\\\", \\\"phone\\\", \\\"tablet\\\"], \\\"brands\\\": [\\\"Dell\\\", \\\"Apple\\\", \\\"Samsung\\\"]},\\n            \\\"clothing\\\": {\\\"keywords\\\": [\\\"dress\\\", \\\"shirt\\\", \\\"pants\\\"], \\\"brands\\\": [\\\"Zara\\\", \\\"H&M\\\"]}\\n        }\\n        self.procedural_memory = {\\n            \\\"RECOMMENDATION_FLOW\\\": [\\\"get_preferences\\\", \\\"search_products\\\", \\\"reason_recommendations\\\", \\\"display_products\\\"],\\n            \\\"PURCHASE_FLOW\\\": [\\\"check_inventory\\\", \\\"process_payment\\\", \\\"confirm_order\\\"]\\n        }\\n        self.user_preferences = {\\\"U001\\\": \\\"electronics\\\"}\\n\\n    def add_to_working_memory(self, key, value):\\n        self.working_memory[key] = value\\n\\n    def get_from_working_memory(self, key):\\n        return self.working_memory.get(key)\\n\\n    def add_episodic_memory(self, event):\\n        self.episodic_memory.append(event)\\n\\n    def get_user_preferences(self):\\n        return self.user_preferences.get(self.user_id, \\\"general\\\")\\n\\n    def update_user_preferences(self, new_pref):\\n        self.user_preferences[self.user_id] = new_pref\\n        print(f\\\"[Memory] User {self.user_id} preferences updated to: {new_pref}\\\")\\n\\nclass KnowledgeBase:\\n    def __init__(self):\\n        self.product_catalog = {\\n            \\\"Dell XPS 15\\\": {\\\"category\\\": \\\"electronics\\\", \\\"price\\\": 1800, \\\"stock\\\": 5, \\\"description\\\": \\\"Powerful laptop\\\"},\\n            \\\"MacBook Pro\\\": {\\\"category\\\": \\\"electronics\\\", \\\"price\\\": 2200, \\\"stock\\\": 3, \\\"description\\\": \\\"Premium laptop\\\"},\\n            \\\"Summer Floral Dress\\\": {\\\"category\\\": \\\"clothing\\\", \\\"price\\\": 50, \\\"stock\\\": 10, \\\"description\\\": \\\"Light summer dress\\\"},\\n            \\\"Evening Gown\\\": {\\\"category\\\": \\\"clothing\\\", \\\"price\\\": 200, \\\"stock\\\": 2, \\\"description\\\": \\\"Elegant gown\\\"}\\n        }\\n\\n    def retrieve_product_info(self, product_name):\\n        return self.product_catalog.get(product_name, {\\\"error\\\": \\\"Product not found\\\"})\\n\\n    def search_products(self, query):\\n        results = []\\n        for name, info in self.product_catalog.items():\\n            if query.lower() in name.lower() or query.lower() in info['description'].lower() or query.lower() in info['category'].lower():\\n                results.append(name)\\n        return results\\n\\nclass Tool(abc.ABC):\\n    @abc.abstractmethod\\n    def name(self):\\n        pass\\n\\n    @abc.abstractmethod\\n    def execute(self, *args, **kwargs):\\n        pass\\n\\nclass ProductSearchTool(Tool):\\n    def name(self):\\n        return \\\"ProductSearchTool\\\"\\n\\n    def execute(self, query, knowledge_base):\\n        print(f\\\"[Tool:ProductSearch] Searching for '{query}'\\\")\\n        return knowledge_base.search_products(query)\\n\\nclass InventoryCheckerTool(Tool):\\n    def name(self):\\n        return \\\"InventoryCheckerTool\\\"\\n\\n    def execute(self, product_name, knowledge_base):\\n        print(f\\\"[Tool:InventoryChecker] Checking stock for '{product_name}'\\\")\\n        info = knowledge_base.retrieve_product_info(product_name)\\n        return info.get(\\\"stock\\\", 0)\\n\\nclass PaymentGatewaySimulator(Tool):\\n    def name(self):\\n        return \\\"PaymentGatewaySimulator\\\"\\n\\n    def execute(self, amount, user_id, product_name):\\n        print(f\\\"[Tool:PaymentGateway] Simulating payment of ${amount} for {product_name} by user {user_id}\\\")\\n        # In a real system, this would interact with a payment API\\n        return {\\\"status\\\": \\\"success\\\", \\\"transaction_id\\\": f\\\"TXN_{hash(user_id + product_name)}\\\"}\\n\\nclass ShoppingAssistantAgent:\\n    def __init__(self, user_id):\\n        self.user_id = user_id\\n        self.llm = LLMAdapter()\\n        self.memory = MemorySystem(user_id)\\n        self.knowledge_base = KnowledgeBase()\\n        self.tools = {\\n            \\\"product_search\\\": ProductSearchTool(),\\n            \\\"inventory_checker\\\": InventoryCheckerTool(),\\n            \\\"payment_gateway\\\": PaymentGatewaySimulator()\\n        }\\n        self.actions_taken = []\\n\\n    def _plan_and_execute(self, intent, query=None, product_name=None, amount=None):\\n        plan = []\\n        results = {}\\n        if intent == \\\"PRODUCT_RECOMMENDATION\\\" or intent == \\\"PRODUCT_SEARCH\\\":\\n            plan = self.memory.procedural_memory[\\\"RECOMMENDATION_FLOW\\\"]\\n            self.memory.add_to_working_memory(\\\"current_query\\\", query)\\n        elif intent == \\\"PURCHASE_INTENT\\\" and product_name and amount:\\n            plan = self.memory.procedural_memory[\\\"PURCHASE_FLOW\\\"]\\n            self.memory.add_to_working_memory(\\\"product_to_buy\\\", product_name)\\n            self.memory.add_to_working_memory(\\\"purchase_amount\\\", amount)\\n        else:\\n            print(\\\"[Agent] No specific plan for this intent.\\\")\\n            return {}\\n\\n        print(f\\\"[Agent] Executing plan for {intent}: {plan}\\\")\\n\\n        for step in plan:\\n            if step == \\\"get_preferences\\\":\\n                user_pref = self.memory.get_user_preferences()\\n                self.memory.add_to_working_memory(\\\"user_preferences\\\", user_pref)\\n                self.actions_taken.append(f\\\"Retrieved user preferences: {user_pref}\\\")\\n            elif step == \\\"search_products\\\":\\n                current_query = self.memory.get_from_working_memory(\\\"current_query\\\")\\n                search_results = self.tools[\\\"product_search\\\"].execute(current_query, self.knowledge_base)\\n                self.memory.add_to_working_memory(\\\"search_results\\\", search_results)\\n                self.actions_taken.append(f\\\"Searched for '{current_query}', found: {search_results}\\\")\\n            elif step == \\\"reason_recommendations\\\":\\n                user_pref = self.memory.get_from_working_memory(\\\"user_preferences\\\")\\n                search_results = self.memory.get_from_working_memory(\\\"search_results\\\")\\n                product_catalog_info = self.knowledge_base.product_catalog\\n                recommendations = self.llm.reason_recommendations(user_pref, search_results, product_catalog_info)\\n                self.memory.add_to_working_memory(\\\"recommendations\\\", recommendations)\\n                self.actions_taken.append(f\\\"Generated recommendations: {recommendations}\\\")\\n                results[\\\"recommendations\\\"] = recommendations\\n            elif step == \\\"display_products\\\":\\n                # This step is handled by the final response generation\\n                pass\\n            elif step == \\\"check_inventory\\\":\\n                prod_name = self.memory.get_from_working_memory(\\\"product_to_buy\\\")\\n                stock = self.tools[\\\"inventory_checker\\\"].execute(prod_name, self.knowledge_base)\\n                self.memory.add_to_working_memory(\\\"product_stock\\\", stock)\\n                self.actions_taken.append(f\\\"Checked inventory for '{prod_name}': {stock} in stock\\\")\\n                if stock <= 0:\\n                    results[\\\"purchase_status\\\"] = \\\"failed: out of stock\\\"\\n                    return results # Stop plan if out of stock\\n            elif step == \\\"process_payment\\\":\\n                prod_name = self.memory.get_from_working_memory(\\\"product_to_buy\\\")\\n                amount_to_pay = self.knowledge_base.retrieve_product_info(prod_name).get('price')\\n                if amount_to_pay:\\n                    payment_result = self.tools[\\\"payment_gateway\\\"].execute(amount_to_pay, self.user_id, prod_name)\\n                    self.memory.add_to_working_memory(\\\"payment_result\\\", payment_result)\\n                    self.actions_taken.append(f\\\"Processed payment for {prod_name}: {payment_result['status']}\\\")\\n                    results[\\\"purchase_status\\\"] = payment_result[\\\"status\\\"]\\n                else:\\n                    results[\\\"purchase_status\\\"] = \\\"failed: price not found\\\"\\n            elif step == \\\"confirm_order\\\":\\n                if results.get(\\\"purchase_status\\\") == \\\"success\\\":\\n                    self.actions_taken.append(\\\"Order confirmed.\\\")\\n                    self.memory.add_episodic_memory({\\\"user_id\\\": self.user_id, \\\"type\\\": \\\"purchase\\\",\\n                                                     \\\"product\\\": self.memory.get_from_working_memory(\\\"product_to_buy\\\"),\\n                                                     \\\"transaction_id\\\": self.memory.get_from_working_memory(\\\"payment_result\\\").get(\\\"transaction_id\\\")})\\n        return results\\n\\n    def verify_action(self, action_type, context):\\n        print(f\\\"[Agent] Verifying '{action_type}' with context: {context}\\\")\\n        if action_type == \\\"purchase\\\" and context.get(\\\"stock\\\", 0) <= 0:\\n            print(\\\"[Agent] Verification failed: Item is out of stock.\\\")\\n            return False\\n        if action_type == \\\"recommendation\\\" and not context.get(\\\"recommendations\\\"): # Simple check\\n            print(\\\"[Agent] Verification warning: No recommendations generated.\\\")\\n        return True\\n\\n    def learn_from_feedback(self, feedback_type, data):\\n        if feedback_type == \\\"positive_recommendation\\\":\\n            current_pref = self.memory.get_user_preferences()\\n            if data not in current_pref:\\n                self.memory.update_user_preferences(data) # Simplified: just add a new preference\\n        self.memory.add_episodic_memory({\\\"user_id\\\": self.user_id, \\\"type\\\": \\\"feedback\\\", \\\"feedback\\\": feedback_type, \\\"data\\\": data})\\n        print(f\\\"[Agent] Learning: Processed feedback '{feedback_type}' for user {self.user_id}.\\\")\\n\\n    def process_user_request(self, query, product_name=None, quantity=1):\\n        intent = self.llm.understand_intent(query)\\n        self.actions_taken = []\\n\\n        if intent == \\\"PRODUCT_RECOMMENDATION\\\" or intent == \\\"PRODUCT_SEARCH\\\":\\n            results = self._plan_and_execute(intent, query=query)\\n            self.verify_action(\\\"recommendation\\\", results)\\n            response_context = f\\\"Your search for '{query}' and personalized recommendations:\\\"\\n            print(self.llm.generate_response(response_context, results.get(\\\"recommendations\\\", \\\"No specific recommendations.\\\")))\\n            if results.get(\\\"recommendations\\\"): # Simulate feedback\\n                self.learn_from_feedback(\\\"positive_recommendation\\\", results[\\\"recommendations\\\"][0])\\n\\n        elif intent == \\\"PURCHASE_INTENT\\\" and product_name:\\n            product_info = self.knowledge_base.retrieve_product_info(product_name)\\n            if \\\"error\\\" in product_info:\\n                print(f\\\"[Agent] Error: {product_info['error']}\\\")\\n                return\\n            amount = product_info['price'] * quantity\\n            results = self._plan_and_execute(intent, product_name=product_name, amount=amount)\\n            self.verify_action(\\\"purchase\\\", {\\\"stock\\\": self.memory.get_from_working_memory(\\\"product_stock\\\")})\\n            response_context = f\\\"Attempting to purchase {quantity}x {product_name} for ${amount}.\\\"\\n            print(self.llm.generate_response(response_context, f\\\"Purchase Status: {results.get('purchase_status')}\\\"))\\n\\n        else:\\n            print(\\\"[Agent] I'm not sure how to handle that request. Can you please rephrase?\\\")\\n\\n# Real-world Usage & Simulation Pattern\\n\\nprint(\\\"\\\\n--- Simulation 1: User looking for a laptop ---\\\")\\nuser_agent_1 = ShoppingAssistantAgent(user_id=\\\"U001\\\")\\nuser_agent_1.process_user_request(\\\"I'm looking for a new laptop, can you recommend some?\\\")\\n\\nprint(\\\"\\\\n--- Simulation 2: User searching for a specific dress ---\\\")\\nuser_agent_2 = ShoppingAssistantAgent(user_id=\\\"U002\\\")\\nuser_agent_2.memory.update_user_preferences(\\\"clothing\\\") # Simulate prior learning\\nuser_agent_2.process_user_request(\\\"Search for a summer dress.\\\")\\n\\nprint(\\\"\\\\n--- Simulation 3: User attempting to buy an item ---\\\")\\nuser_agent_3 = ShoppingAssistantAgent(user_id=\\\"U001\\\")\\nuser_agent_3.process_user_request(\\\"I want to add Dell XPS 15 to my cart and buy it.\\\", product_name=\\\"Dell XPS 15\\\", quantity=1)\\n\\nprint(\\\"\\\\n--- Simulation 4: User attempting to buy an out-of-stock item (simulated) ---\\\")\\nuser_agent_4 = ShoppingAssistantAgent(user_id=\\\"U004\\\")\\nuser_agent_4.knowledge_base.product_catalog[\\\"MacBook Pro\\\"][\\\"stock\\\"] = 0 # Simulate out of stock\\nuser_agent_4.process_user_request(\\\"I want to buy a MacBook Pro.\\\", product_name=\\\"MacBook Pro\\\", quantity=1)\\n\\nprint(\\\"\\\\n--- Simulation 5: User preferences after learning ---\\\")\\nprint(f\\\"U001 current preferences: {user_agent_1.memory.get_user_preferences()}\\\")\\nprint(f\\\"U002 current preferences: {user_agent_2.memory.get_user_preferences()}\\\")\\n\",\n",
      "  \"import abc\\nimport datetime\\n\\nclass LLMAdapter:\\n    def __init__(self, model_name=\\\"Simulated_LLM\\\"):\\n        self.model_name = model_name\\n\\n    def understand_intent(self, query):\\n        print(f\\\"[{self.model_name}] Understanding intent for: '{query}'\\\")\\n        if \\\"suspicious\\\" in query.lower() or \\\"fraud\\\" in query.lower() or \\\"unusual\\\" in query.lower():\\n            return \\\"FRAUD_ALERT\\\"\\n        if \\\"balance\\\" in query.lower() or \\\"transactions\\\" in query.lower():\\n            return \\\"ACCOUNT_INQUIRY\\\"\\n        return \\\"GENERAL_INQUIRY\\\"\\n\\n    def reason_fraud_risk(self, transaction_details, fraud_patterns, customer_history):\\n        print(f\\\"[{self.model_name}] Reasoning fraud risk for transaction: {transaction_details['id']}\\\")\\n        print(f\\\"  Considering fraud patterns: {fraud_patterns[:50]}...\\\")\\n        print(f\\\"  Considering customer history: {customer_history[:50]}...\\\")\\n\\n        risk_score = 0\\n        reasons = []\\n\\n        if transaction_details.get('amount') > 5000:\\n            risk_score += 3\\n            reasons.append(\\\"High transaction amount.\\\")\\n        if transaction_details.get('location') == \\\"Nigeria\\\" and transaction_details.get('country_of_origin') == \\\"USA\\\":\\n            risk_score += 5\\n            reasons.append(\\\"Unusual international transaction.\\\")\\n        if transaction_details.get('type') == \\\"large_cash_withdrawal\\\" and \\\"frequent_withdrawals\\\" in fraud_patterns:\\n            risk_score += 4\\n            reasons.append(\\\"Matches known frequent withdrawal fraud pattern.\\\")\\n\\n        if risk_score >= 5:\\n            return {\\\"risk\\\": \\\"HIGH\\\", \\\"score\\\": risk_score, \\\"reasons\\\": reasons}\\n        elif risk_score >= 2:\\n            return {\\\"risk\\\": \\\"MEDIUM\\\", \\\"score\\\": risk_score, \\\"reasons\\\": reasons}\\n        return {\\\"risk\\\": \\\"LOW\\\", \\\"score\\\": risk_score, \\\"reasons\\\": reasons}\\n\\n    def generate_customer_message(self, customer_name, transaction_id, risk_level, proposed_actions):\\n        message = f\\\"Dear {customer_name},\\\\n\\\"\\n        message += f\\\"We detected unusual activity on your account, specifically transaction {transaction_id}.\\\\n\\\"\\n        message += f\\\"Our analysis indicates a {risk_level} risk level.\\\\n\\\"\\n        if \\\"freeze_account\\\" in proposed_actions:\\n            message += \\\"For your security, your account has been temporarily frozen. Please contact us immediately.\\\\n\\\"\\n        elif \\\"monitor_account\\\" in proposed_actions:\\n            message += \\\"We are currently monitoring your account. No immediate action is required from your side, but please review your recent transactions.\\\\n\\\"\\n        else:\\n            message += \\\"Please contact our fraud department at your earliest convenience to verify this activity.\\\\n\\\"\\n        message += \\\"Thank you, Bank of AI.\\\"\\n        return message\\n\\nclass MemorySystem:\\n    def __init__(self):\\n        self.working_memory = {}\\n        self.episodic_memory = [] # Past alerts, customer interactions\\n        self.semantic_memory = {\\n            \\\"FRAUD_TYPOLOGIES\\\": [\\n                \\\"unusual_location_transaction\\\",\\n                \\\"high_value_single_transaction\\\",\\n                \\\"frequent_withdrawals_unusual_times\\\"\\n            ],\\n            \\\"REGULATORY_COMPLIANCE\\\": \\\"All fraud investigations must follow AML/KYC guidelines.\\\"\\n        }\\n        self.procedural_memory = {\\n            \\\"FRAUD_INVESTIGATION_FLOW\\\": [\\n                \\\"query_transaction_details\\\",\\n                \\\"analyze_patterns\\\",\\n                \\\"assess_risk\\\",\\n                \\\"propose_actions\\\",\\n                \\\"verify_compliance\\\",\\n                \\\"notify_customer\\\"\\n            ],\\n            \\\"ACCOUNT_INQUIRY_FLOW\\\": [\\n                \\\"query_account_balance\\\",\\n                \\\"query_recent_transactions\\\",\\n                \\\"respond_to_customer\\\"\\n            ]\\n        }\\n\\n    def add_to_working_memory(self, key, value):\\n        self.working_memory[key] = value\\n\\n    def get_from_working_memory(self, key):\\n        return self.working_memory.get(key)\\n\\n    def add_episodic_memory(self, event):\\n        self.episodic_memory.append(event)\\n\\n    def get_customer_history(self, customer_id):\\n        return [e for e in self.episodic_memory if e.get('customer_id') == customer_id]\\n\\nclass KnowledgeBase:\\n    def __init__(self):\\n        self.transaction_db = {\\n            \"TXN001\": {\"customer_id\": \"C101\", \"amount\": 1500, \"location\": \"London\", \"country_of_origin\": \"UK\", \"type\": \"online_purchase\", \"timestamp\": \"2023-10-26T10:00:00\"},\\n            \"TXN002\": {\"customer_id\": \"C102\", \"amount\": 6000, \"location\": \"Nigeria\", \"country_of_origin\": \"USA\", \"type\": \"international_transfer\", \"timestamp\": \"2023-10-26T11:30:00\"},\\n            \"TXN003\": {\"customer_id\": \"C101\", \"amount\": 200, \"location\": \"London\", \"country_of_origin\": \"UK\", \"type\": \"ATM_withdrawal\", \"timestamp\": \"2023-10-26T12:00:00\"}\\n        }\\n        self.fraud_signatures = {\\n            \"unusual_location_transfer\": \"High-value international transfer from unusual country for customer.\",\\n            \"large_single_transaction\": \"Transaction significantly larger than average for customer.\",\\n            \"multiple_failed_attempts\": \"Multiple failed login/transaction attempts followed by success.\"\\n        }\\n\\n    def get_transaction_details(self, transaction_id):\\n        return self.transaction_db.get(transaction_id)\\n\\n    def get_fraud_pattern_description(self, pattern_key):\\n        return self.fraud_signatures.get(pattern_key, \\\"\\\")\\n\\nclass Tool(abc.ABC):\\n    @abc.abstractmethod\\n    def name(self):\\n        pass\\n\\n    @abc.abstractmethod\\n    def execute(self, *args, **kwargs):\\n        pass\\n\\nclass TransactionQueryTool(Tool):\\n    def name(self):\\n        return \\\"TransactionQueryTool\\\"\\n\\n    def execute(self, transaction_id, knowledge_base):\\n        print(f\\\"[Tool:TransactionQuery] Querying details for transaction: {transaction_id}\\\")\\n        return knowledge_base.get_transaction_details(transaction_id)\\n\\nclass FraudPatternAnalyzerTool(Tool):\\n    def name(self):\\n        return \\\"FraudPatternAnalyzerTool\\\"\\n\\n    def execute(self, transaction_details, memory_system):\\n        print(f\\\"[Tool:FraudPatternAnalyzer] Analyzing transaction {transaction_details['id']} for patterns.\\\")\\n        detected_patterns = []\\n        if transaction_details.get('amount') > 5000 and transaction_details.get('type') == 'international_transfer':\\n            detected_patterns.append(\\\"unusual_location_transfer\\\")\\n        if transaction_details.get('amount') > 1000 and transaction_details.get('customer_id') == 'C101': # Example for C101\\n            detected_patterns.append(\\\"large_single_transaction\\\")\\n        return detected_patterns\\n\\nclass CustomerCommunicationTool(Tool):\\n    def name(self):\\n        return \\\"CustomerCommunicationTool\\\"\\n\\n    def execute(self, customer_id, message):\\n        print(f\\\"[Tool:CustomerCommunication] Sending message to customer {customer_id}: '{message[:50]}...'\\\\n\\\")\\n        return {\\\"status\\\": \\\"sent\\\", \\\"customer_id\\\": customer_id}\\n\\nclass AccountActionTool(Tool):\\n    def name(self):\\n        return \\\"AccountActionTool\\\"\\n\\n    def execute(self, customer_id, action_type):\\n        print(f\\\"[Tool:AccountAction] Executing action '{action_type}' for customer {customer_id}\\\")\\n        if action_type == \\\"freeze_account\\\":\\n            return {\\\"status\\\": \\\"success\\\", \\\"action\\\": \\\"account_frozen\\\"}\\n        elif action_type == \\\"monitor_account\\\":\\n            return {\\\"status\\\": \\\"success\\\", \\\"action\\\": \\\"account_monitored\\\"}\\n        return {\\\"status\\\": \\\"failed\\\", \\\"action\\\": \\\"unknown\\\"}\\n\\nclass FraudDetectionAgent:\\n    def __init__(self):\\n        self.llm = LLMAdapter()\\n        self.memory = MemorySystem()\\n        self.knowledge_base = KnowledgeBase()\\n        self.tools = {\\n            \\\"transaction_query\\\": TransactionQueryTool(),\\n            \\\"fraud_analyzer\\\": FraudPatternAnalyzerTool(),\\n            \\\"customer_comm\\\": CustomerCommunicationTool(),\\n            \\\"account_action\\\": AccountActionTool()\\n        }\\n        self.actions_taken = []\\n\\n    def _plan_and_execute(self, intent, transaction_id=None, customer_id=None):\\n        plan = []\\n        results = {}\\n        if intent == \\\"FRAUD_ALERT\\\" and transaction_id:\\n            plan = self.memory.procedural_memory[\\\"FRAUD_INVESTIGATION_FLOW\\\"]\\n            self.memory.add_to_working_memory(\\\"current_transaction_id\\\", transaction_id)\\n        elif intent == \\\"ACCOUNT_INQUIRY\\\" and customer_id:\\n            plan = self.memory.procedural_memory[\\\"ACCOUNT_INQUIRY_FLOW\\\"]\\n            self.memory.add_to_working_memory(\\\"current_customer_id\\\", customer_id)\\n        else:\\n            print(\\\"[Agent] No specific plan for this intent.\\\")\\n            return {}\\n\\n        print(f\\\"[Agent] Executing plan for {intent}: {plan}\\\")\\n\\n        for step in plan:\\n            if step == \\\"query_transaction_details\\\":\\n                tx_id = self.memory.get_from_working_memory(\\\"current_transaction_id\\\")\\n                tx_details = self.tools[\\\"transaction_query\\\"].execute(tx_id, self.knowledge_base)\\n                self.memory.add_to_working_memory(\\\"transaction_details\\\", tx_details)\\n                self.actions_taken.append(f\\\"Queried transaction {tx_id}\\\")\\n            elif step == \\\"analyze_patterns\\\":\\n                tx_details = self.memory.get_from_working_memory(\\\"transaction_details\\\")\\n                detected_patterns = self.tools[\\\"fraud_analyzer\\\"].execute(tx_details, self.memory)\\n                self.memory.add_to_working_memory(\\\"detected_fraud_patterns\\\", detected_patterns)\\n                self.actions_taken.append(f\\\"Analyzed for patterns: {detected_patterns}\\\")\\n            elif step == \\\"assess_risk\\\":\\n                tx_details = self.memory.get_from_working_memory(\\\"transaction_details\\\")\\n                fraud_patterns_info = [self.knowledge_base.get_fraud_pattern_description(p) for p in self.memory.get_from_working_memory(\\\"detected_fraud_patterns\\\")]\\n                customer_history = self.memory.get_customer_history(tx_details['customer_id'])\\n                risk_assessment = self.llm.reason_fraud_risk(tx_details, \\\", \\\".join(fraud_patterns_info), str(customer_history))\\n                self.memory.add_to_working_memory(\\\"risk_assessment\\\", risk_assessment)\\n                self.actions_taken.append(f\\\"Assessed risk: {risk_assessment['risk']} (Score: {risk_assessment['score']})\\\")\\n                results[\\\"risk_assessment\\\"] = risk_assessment\\n            elif step == \\\"propose_actions\\\":\\n                risk_level = self.memory.get_from_working_memory(\\\"risk_assessment\\\")['risk']\\n                proposed_actions = []\\n                if risk_level == \\\"HIGH\\\":\\n                    proposed_actions.append(\\\"freeze_account\\\")\\n                elif risk_level == \\\"MEDIUM\\\":\\n                    proposed_actions.append(\\\"monitor_account\\\")\\n                self.memory.add_to_working_memory(\\\"proposed_actions\\\", proposed_actions)\\n                self.actions_taken.append(f\\\"Proposed actions: {proposed_actions}\\\")\\n                results[\\\"proposed_actions\\\"] = proposed_actions\\n            elif step == \\\"verify_compliance\\\":\\n                # This is a simplified check. In reality, it involves complex rules.\\n                is_compliant = \\\"freeze_account\\\" not in self.memory.get_from_working_memory(\\\"proposed_actions\\\") or \\\\\\n                                self.memory.semantic_memory[\\\"REGULATORY_COMPLIANCE\\\"] is not None\\n                self.memory.add_to_working_memory(\\\"is_compliant\\\", is_compliant)\\n                self.actions_taken.append(f\\\"Verified compliance: {is_compliant}\\\")\\n                if not is_compliant: # If not compliant, override actions to just notify\\n                    print(\\\"[Agent] Compliance check failed. Overriding actions to only notify.\\\")\\n                    self.memory.add_to_working_memory(\\\"proposed_actions\\\", [])\\n            elif step == \\\"notify_customer\\\":\\n                tx_details = self.memory.get_from_working_memory(\\\"transaction_details\\\")\\n                risk_level = self.memory.get_from_working_memory(\\\"risk_assessment\\\")['risk']\\n                proposed_actions = self.memory.get_from_working_memory(\\\"proposed_actions\\\")\\n                customer_message = self.llm.generate_customer_message(tx_details['customer_id'], tx_details['id'], risk_level, proposed_actions)\\n                comm_result = self.tools[\\\"customer_comm\\\"].execute(tx_details['customer_id'], customer_message)\\n                self.actions_taken.append(f\\\"Customer notified (Status: {comm_result['status']})\\\")\\n                if \\\"freeze_account\\\" in proposed_actions:\\n                    action_result = self.tools[\\\"account_action\\\"].execute(tx_details['customer_id'], \\\"freeze_account\\\")\\n                    self.actions_taken.append(f\\\"Account frozen (Status: {action_result['status']})\\\")\\n\\n        return results\\n\\n    def verify_action_grounding(self, action_type, context):\\n        print(f\\\"[Agent] Verifying grounding for action '{action_type}' with context: {context}\\\")\\n        if action_type == \\\"freeze_account\\\":\\n            if context.get('risk_level') != \\\"HIGH\\\":\\n                print(\\\"[Agent] Warning: Account freeze proposed for non-HIGH risk. Requires manual override.\\\")\\n                return False\\n        return True\\n\\n    def learn_from_case(self, case_summary):\\n        self.memory.add_episodic_memory(case_summary)\\n        print(f\\\"[Agent] Learning: Case summary added to episodic memory.\\\")\\n\\n    def process_alert(self, query, transaction_id=None, customer_id=None):\\n        intent = self.llm.understand_intent(query)\\n        self.actions_taken = []\\n\\n        if intent == \\\"FRAUD_ALERT\\\" and transaction_id:\\n            print(f\\\"[Agent] Processing fraud alert for transaction: {transaction_id}\\\")\\n            self.memory.add_episodic_memory({\\\"type\\\": \\\"fraud_alert_received\\\", \\\"transaction_id\\\": transaction_id, \\\"timestamp\\\": str(datetime.datetime.now())})\\n\\n            results = self._plan_and_execute(intent, transaction_id=transaction_id)\\n\\n            if results.get(\\\"proposed_actions\\\") and \\\"freeze_account\\\" in results[\\\"proposed_actions\\\"]:\\n                self.verify_action_grounding(\\\"freeze_account\\\", {\\\"risk_level\\\": results['risk_assessment']['risk']})\\n\\n            case_summary = {\\n                \\\"transaction_id\\\": transaction_id,\\n                \\\"query\\\": query,\\n                \\\"risk_assessment\\\": results.get(\\\"risk_assessment\\\"),\\n                \\\"actions_taken\\\": self.actions_taken,\\n                \\\"outcome\\\": \\\"alert_processed\\\"\\n            }\\n            self.learn_from_case(case_summary)\\n\\n        elif intent == \\\"ACCOUNT_INQUIRY\\\" and customer_id:\\n            print(f\\\"[Agent] Processing account inquiry for customer: {customer_id}\\\")\\n            # Simplified for brevity, but would follow ACCOUNT_INQUIRY_FLOW\\n            self.actions_taken.append(f\\\"Acknowledged inquiry for {customer_id}\\\")\\n            print(f\\\"[Agent] For customer {customer_id}: Balance $X, Recent transactions Y, Z.\\\")\\n            self.learn_from_case({\\\"customer_id\\\": customer_id, \\\"query\\\": query, \\\"outcome\\\": \\\"inquiry_handled\\\"})\\n\\n        else:\\n            print(\\\"[Agent] Could not process alert/inquiry effectively. Please provide more details.\\\")\\n\\n# Real-world Usage & Simulation Pattern\\n\\n# Scenario 1: High-risk international transfer\\nprint(\\\"\\\\n--- Simulation 1: High-Risk International Transfer ---\\\")\\nfraud_agent_1 = FraudDetectionAgent()\\nfraud_agent_1.process_alert(\\\"Suspicious international transfer detected.\\\", transaction_id=\\\"TXN002\\\")\\n\\n# Scenario 2: Regular transaction (low risk)\\nprint(\\\"\\\\n--- Simulation 2: Regular Transaction ---\\\")\\nfraud_agent_2 = FraudDetectionAgent()\\nfraud_agent_2.process_alert(\\\"Transaction TXN001 was unusual.\\\", transaction_id=\\\"TXN001\\\")\\n\\n# Scenario 3: Account inquiry (customer service aspect)\\nprint(\\\"\\\\n--- Simulation 3: Customer Account Inquiry ---\\\")\\nfraud_agent_3 = FraudDetectionAgent()\\nfraud_agent_3.process_alert(\\\"What is my balance and recent transactions?\\\", customer_id=\\\"C101\\\")\\n\\nprint(\\\"\\\\n--- Simulation 4: Learning from experience ---\\\")\\nprint(f\\\"Episodic memory for fraud_agent_1: {fraud_agent_1.memory.episodic_memory}\\\")\\n\"\n",
      "]\n",
      "Saved Adversarial Agent Interaction pattern examples\n",
      "Saved Comprehensive Black-Box Explainability and Analysis Framework pattern examples\n",
      "Generating 3 code examples for the Holistic LLM Agentic Framework pattern...\n",
      "Generating 3 code examples for the Parallel Tool Execution pattern...\n",
      "Generating 3 code examples for the Adversarial Agent Interaction pattern...\n",
      "Generating 3 code examples for the Comprehensive Black-Box Explainability and Analysis Framework pattern...\n",
      "Error decoding JSON for pattern Parallel Tool Execution: Expecting value: line 1 column 1 (char 0)\n",
      "Output content: json\n",
      "[\n",
      "\"import time\\nimport concurrent.futures\\n\\ndef validate_order(order_id):\\n    time.sleep(0.5)\\n    return f\\\"Order {order_id} validated.\\\"\\n\\ndef process_payment(order_id, amount):\\n    time.sleep(1.5)\\n    return f\\\"Payment of ${amount} for order {order_id} processed.\\\"\\n\\ndef update_inventory(order_id, items):\\n    time.sleep(1.0)\\n    return f\\\"Inventory updated for order {order_id} with items: {items}.\\\"\\n\\ndef generate_shipping_label(order_id, address):\\n    time.sleep(1.2)\\n    return f\\\"Shipping label generated for order {order_id} to {address}.\\\"\\n\\ndef send_confirmation_email(order_id, customer_email):\\n    time.sleep(0.8)\\n    return f\\\"Confirmation email sent for order {order_id} to {customer_email}.\\\"\\n\\ndef log_order_details(order_id, details):\\n    time.sleep(0.3)\\n    return f\\\"Order {order_id} details logged: {details}.\\\"\\n\\ndef process_ecommerce_order(order_id, amount, items, address, customer_email):\\n    print(f\\\"[{time.time():.2f}] Starting order processing for {order_id}...\\\")\\n    validation_result = validate_order(order_id)\\n    print(f\\\"[{time.time():.2f}] {validation_result}\\\")\\n    with concurrent.futures.ThreadPoolExecutor(max_workers=4) as executor:\\n        future_payment = executor.submit(process_payment, order_id, amount)\\n        future_inventory = executor.submit(update_inventory, order_id, items)\\n        future_shipping = executor.submit(generate_shipping_label, order_id, address)\\n        future_email = executor.submit(send_confirmation_email, order_id, customer_email)\\n        payment_result = future_payment.result()\\n        inventory_result = future_inventory.result()\\n        shipping_result = future_shipping.result()\\n        email_result = future_email.result()\\n        print(f\\\"[{time.time():.2f}] {payment_result}\\\")\\n        print(f\\\"[{time.time():.2f}] {inventory_result}\\\")\\n        print(f\\\"[{time.time():.2f}] {shipping_result}\\\")\\n        print(f\\\"[{time.time():.2f}] {email_result}\\\")\\n    log_result = log_order_details(order_id, {\\\"amount\\\": amount, \\\"items\\\": items})\\n    print(f\\\"[{time.time():.2f}] {log_result}\\\")\\n    print(f\\\"[{time.time():.2f}] Order {order_id} processing complete.\\\")\\n\\nif __name__ == \\\"__main__\\\":\\n    process_ecommerce_order(\\\"ORD-12345\\\", 99.99, [\\\"Laptop\\\", \\\"Mouse\\\"], \\\"123 Main St\\\", \\\"customer@example.com\\\")\",\n",
      "\"import time\\nimport concurrent.futures\\n\\ndef register_patient_demographics(patient_id, name, dob):\\n    time.sleep(1.0)\\n    return f\\\"Patient {patient_id} ({name}, {dob}) demographics registered.\\\"\\n\\ndef verify_insurance_eligibility(patient_id, policy_number):\\n    time.sleep(1.8)\\n    return f\\\"Insurance eligibility verified for patient {patient_id} with policy {policy_number}.\\\"\\n\\ndef prepare_patient_portal_access(patient_id, email):\\n    time.sleep(1.2)\\n    return f\\\"Patient portal access prepared for {patient_id} with email {email}.\\\"\\n\\ndef send_welcome_packet(patient_id, address):\\n    time.sleep(1.5)\\n    return f\\\"Welcome packet dispatched for patient {patient_id} to {address}.\\\"\\n\\ndef schedule_initial_consultation(patient_id, doctor_id, date_time):\\n    time.sleep(0.7)\\n    return f\\\"Initial consultation scheduled for patient {patient_id} with Dr. {doctor_id} on {date_time}.\\\"\\n\\ndef onboard_new_patient(patient_id, name, dob, policy_number, email, address, doctor_id, date_time):\\n    print(f\\\"[{time.time():.2f}] Starting patient onboarding for {patient_id}...\\\")\\n    reg_result = register_patient_demographics(patient_id, name, dob)\\n    print(f\\\"[{time.time():.2f}] {reg_result}\\\")\\n    with concurrent.futures.ThreadPoolExecutor(max_workers=4) as executor:\\n        future_insurance = executor.submit(verify_insurance_eligibility, patient_id, policy_number)\\n        future_portal = executor.submit(prepare_patient_portal_access, patient_id, email)\\n        future_welcome = executor.submit(send_welcome_packet, patient_id, address)\\n        future_consultation = executor.submit(schedule_initial_consultation, patient_id, doctor_id, date_time)\\n        insurance_result = future_insurance.result()\\n        portal_result = future_portal.result()\\n        welcome_result = future_welcome.result()\\n        consultation_result = future_consultation.result()\\n        print(f\\\"[{time.time():.2f}] {insurance_result}\\\")\\n        print(f\\\"[{time.time():.2f}] {portal_result}\\\")\\n        print(f\\\"[{time.time():.2f}] {welcome_result}\\\")\\n        print(f\\\"[{time.time():.2f}] {consultation_result}\\\")\\n    print(f\\\"[{time.time():.2f}] Patient {patient_id} onboarding complete.\\\")\\n\\nif __name__ == \\\"__main__\\\":\\n    onboard_new_patient(\\\"PAT-001\\\", \\\"Jane Doe\\\", \\\"1990-05-15\\\", \\\"INS-XYZ123\\\", \\\"jane.doe@example.com\\\", \\\"456 Oak Ave\\\", \\\"Smith\\\", \\\"2023-11-20 10:00\\\")\",\n",
      "\"import time\\nimport concurrent.futures\\n\\ndef validate_transaction_details(transaction_id, amount, account_from, account_to):\\n    time.sleep(0.6)\\n    return f\\\"Transaction {transaction_id} details validated (from {account_from} to {account_to}, amount {amount}).\\\"\\n\\ndef check_for_fraud_patterns(transaction_id, amount, account_from):\\n    time.sleep(2.0)\\n    return f\\\"Fraud check completed for transaction {transaction_id}: No fraud detected.\\\"\\n\\ndef update_account_balance(transaction_id, account_id, amount, transaction_type):\\n    time.sleep(1.5)\\n    return f\\\"Account {account_id} balance updated for transaction {transaction_id} ({transaction_type} {amount}).\\\"\\n\\ndef generate_transaction_receipt(transaction_id, details):\\n    time.sleep(1.0)\\n    return f\\\"Receipt generated for transaction {transaction_id} with details: {details}.\\\"\\n\\ndef notify_user_of_transaction(transaction_id, user_id, message):\\n    time.sleep(0.8)\\n    return f\\\"User {user_id} notified for transaction {transaction_id}: {message}.\\\"\\n\\ndef process_financial_transaction(transaction_id, amount, account_from, account_to, user_id):\\n    print(f\\\"[{time.time():.2f}] Starting transaction processing for {transaction_id}...\\\")\\n    validation_result = validate_transaction_details(transaction_id, amount, account_from, account_to)\\n    print(f\\\"[{time.time():.2f}] {validation_result}\\\")\\n    with concurrent.futures.ThreadPoolExecutor(max_workers=4) as executor:\\n        future_fraud = executor.submit(check_for_fraud_patterns, transaction_id, amount, account_from)\\n        future_update_from = executor.submit(update_account_balance, transaction_id, account_from, amount, \\\"debit\\\")\\n        future_update_to = executor.submit(update_account_balance, transaction_id, account_to, amount, \\\"credit\\\")\\n        future_receipt = executor.submit(generate_transaction_receipt, transaction_id, {\\\"amount\\\": amount, \\\"from\\\": account_from, \\\"to\\\": account_to})\\n        future_notify = executor.submit(notify_user_of_transaction, transaction_id, user_id, f\\\"Transaction of ${amount} to {account_to} successful.\\\")\\n        fraud_result = future_fraud.result()\\n        update_from_result = future_update_from.result()\\n        update_to_result = future_update_to.result()\\n        receipt_result = future_receipt.result()\\n        notify_result = future_notify.result()\\n        print(f\\\"[{time.time():.2f}] {fraud_result}\\\")\\n        print(f\\\"[{time.time():.2f}] {update_from_result}\\\")\\n        print(f\\\"[{time.time():.2f}] {update_to_result}\\\")\\n        print(f\\\"[{time.time():.2f}] {receipt_result}\\\")\\n        print(f\\\"[{time.time():.2f}] {notify_result}\\\")\\n    print(f\\\"[{time.time():.2f}] Transaction {transaction_id} processing complete.\\\")\\n\\nif __name__ == \\\"__main__\\\":\\n    process_financial_transaction(\\\"TXN-78901\\\", 500.00, \\\"ACC-A1\\\", \\\"ACC-B2\\\", \\\"USER-XYZ\\\")\"\n",
      "]\n",
      "Saved Comprehensive Black-Box Explainability and Analysis Framework pattern examples\n",
      "Saved Holistic LLM Agentic Framework pattern examples\n",
      "Saved Adversarial Agent Interaction pattern examples\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[34]\u001b[39m\u001b[32m, line 14\u001b[39m\n\u001b[32m     12\u001b[39m ai_design_patterns_threaded(patterns[:\u001b[32m4\u001b[39m],base_path,pattern_count=\u001b[32m3\u001b[39m,starting_index=i+\u001b[32m6\u001b[39m)\n\u001b[32m     13\u001b[39m ai_design_patterns_threaded(patterns[:\u001b[32m4\u001b[39m],base_path,pattern_count=\u001b[32m3\u001b[39m,starting_index=i+\u001b[32m9\u001b[39m)\n\u001b[32m---> \u001b[39m\u001b[32m14\u001b[39m \u001b[43mai_design_patterns_threaded\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpatterns\u001b[49m\u001b[43m[\u001b[49m\u001b[43m:\u001b[49m\u001b[32;43m4\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43mbase_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43mpattern_count\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m3\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43mstarting_index\u001b[49m\u001b[43m=\u001b[49m\u001b[43mi\u001b[49m\u001b[43m+\u001b[49m\u001b[32;43m12\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[32]\u001b[39m\u001b[32m, line 13\u001b[39m, in \u001b[36mai_design_patterns_threaded\u001b[39m\u001b[34m(patterns, base_path, pattern_count, starting_index)\u001b[39m\n\u001b[32m     11\u001b[39m     t.start()\n\u001b[32m     12\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m t \u001b[38;5;129;01min\u001b[39;00m threads:\n\u001b[32m---> \u001b[39m\u001b[32m13\u001b[39m     \u001b[43mt\u001b[49m\u001b[43m.\u001b[49m\u001b[43mjoin\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/usr/lib/python3.12/threading.py:1147\u001b[39m, in \u001b[36mThread.join\u001b[39m\u001b[34m(self, timeout)\u001b[39m\n\u001b[32m   1144\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\u001b[33m\"\u001b[39m\u001b[33mcannot join current thread\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m   1146\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m timeout \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1147\u001b[39m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_wait_for_tstate_lock\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1148\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m   1149\u001b[39m     \u001b[38;5;66;03m# the behavior of a negative timeout isn't documented, but\u001b[39;00m\n\u001b[32m   1150\u001b[39m     \u001b[38;5;66;03m# historically .join(timeout=x) for x<0 has acted as if timeout=0\u001b[39;00m\n\u001b[32m   1151\u001b[39m     \u001b[38;5;28mself\u001b[39m._wait_for_tstate_lock(timeout=\u001b[38;5;28mmax\u001b[39m(timeout, \u001b[32m0\u001b[39m))\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/usr/lib/python3.12/threading.py:1167\u001b[39m, in \u001b[36mThread._wait_for_tstate_lock\u001b[39m\u001b[34m(self, block, timeout)\u001b[39m\n\u001b[32m   1164\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m\n\u001b[32m   1166\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1167\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[43mlock\u001b[49m\u001b[43m.\u001b[49m\u001b[43macquire\u001b[49m\u001b[43m(\u001b[49m\u001b[43mblock\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m:\n\u001b[32m   1168\u001b[39m         lock.release()\n\u001b[32m   1169\u001b[39m         \u001b[38;5;28mself\u001b[39m._stop()\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "base_path = \"/home/hasinthaka/Documents/Projects/AI/AI Pattern Mining/Pattern Validator/reposistories/AI Patterns\"\n",
    "pattern_list_path = \"/home/hasinthaka/Documents/Projects/AI/AI Pattern Mining/Pattern Validator/data/summarized_patterns.json\"\n",
    "\n",
    "with open(pattern_list_path, \"r\") as file:\n",
    "    patterns = json.load(file)\n",
    "\n",
    "i = 17\n",
    "ai_design_patterns_threaded(patterns[:4],base_path,pattern_count=3,starting_index=i)\n",
    "ai_design_patterns_threaded(patterns[:4],base_path,pattern_count=3,starting_index=i+3)\n",
    "ai_design_patterns_threaded(patterns[:4],base_path,pattern_count=3,starting_index=i+6)\n",
    "ai_design_patterns_threaded(patterns[:4],base_path,pattern_count=3,starting_index=i+9)\n",
    "ai_design_patterns_threaded(patterns[:4],base_path,pattern_count=3,starting_index=i+12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e97d7b9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "output = generate_code(\"Singleton\", 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c273d144",
   "metadata": {},
   "outputs": [],
   "source": [
    "json_output = json.loads(output.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1f8bf6eb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['class ShoppingCartManager:\\n    _instance = None\\n\\n    def __new__(cls):\\n        if cls._instance is None:\\n            cls._instance = super().__new__(cls)\\n            cls._instance.items = {}\\n            print(\"New ShoppingCartManager instance created.\")\\n        else:\\n            print(\"Existing ShoppingCartManager instance returned.\")\\n        return cls._instance\\n\\n    def add_item(self, item_id, quantity):\\n        if not isinstance(item_id, str) or not isinstance(quantity, int) or quantity <= 0:\\n            print(\"Invalid item_id or quantity.\")\\n            return\\n        self.items[item_id] = self.items.get(item_id, 0) + quantity\\n        print(f\"Added {quantity} of \\'{item_id}\\'. Current cart: {self.items}\")\\n\\n    def remove_item(self, item_id, quantity):\\n        if not isinstance(item_id, str) or not isinstance(quantity, int) or quantity <= 0:\\n            print(\"Invalid item_id or quantity.\")\\n            return\\n        if item_id in self.items:\\n            self.items[item_id] -= quantity\\n            if self.items[item_id] <= 0:\\n                del self.items[item_id]\\n            print(f\"Removed {quantity} of \\'{item_id}\\'. Current cart: {self.items}\")\\n        else:\\n            print(f\"Item \\'{item_id}\\' not found in cart.\")\\n\\n    def get_cart_contents(self):\\n        return dict(self.items)\\n\\n    def checkout(self):\\n        if not self.items:\\n            print(\"Cart is empty. Nothing to checkout.\")\\n            return False\\n        print(\"Processing checkout for items:\")\\n        for item, qty in self.items.items():\\n            print(f\"  - {qty} x {item}\")\\n        self.items.clear()\\n        print(\"Checkout complete. Cart cleared.\")\\n        return True\\n\\n\\n# Real-world usage simulation: E-commerce application\\n# A user should have only one active shopping cart instance.\\n\\nprint(\"--- User Session 1: Adding items to cart ---\")\\nuser_cart_session1 = ShoppingCartManager()\\nuser_cart_session1.add_item(\"Laptop Pro X\", 1)\\nuser_cart_session1.add_item(\"Wireless Mouse\", 2)\\n\\nprint(\"\\\\n--- User Session 2 (e.g., another browser tab or page refresh) ---\")\\n# Even if the user navigates or reloads, they should get the same cart instance.\\nuser_cart_session2 = ShoppingCartManager()\\nuser_cart_session2.add_item(\"USB-C Hub\", 1)\\n\\nprint(f\"\\\\nAre both cart sessions referring to the same object? {user_cart_session1 is user_cart_session2}\")\\n\\nprint(\"\\\\n--- Cart contents from user_cart_session1 ---\")\\nprint(user_cart_session1.get_cart_contents())\\n\\nprint(\"\\\\n--- Cart contents from user_cart_session2 (should be identical) ---\")\\nprint(user_cart_session2.get_cart_contents())\\n\\nuser_cart_session1.remove_item(\"Wireless Mouse\", 1)\\nprint(\"\\\\n--- Cart contents after removal from session1 (reflected in session2) ---\")\\nprint(user_cart_session2.get_cart_contents())\\n\\nprint(\"\\\\n--- Proceeding to checkout ---\")\\nuser_cart_session2.checkout()\\n\\nprint(\"\\\\n--- Verifying cart after checkout (should be empty) ---\")\\nprint(user_cart_session1.get_cart_contents())\\n',\n",
       " 'class SingletonMeta(type):\\n    _instances = {}\\n\\n    def __call__(cls, *args, **kwargs):\\n        if cls not in cls._instances:\\n            cls._instances[cls] = super().__call__(*args, **kwargs)\\n        return cls._instances[cls]\\n\\nclass HospitalLogSystem(metaclass=SingletonMeta):\\n    def __init__(self, system_name=\"MainHospitalLog\"):\\n        if not hasattr(self, \\'_initialized\\'):\\n            self.system_name = system_name\\n            self.log_entries = []\\n            print(f\"HospitalLogSystem \\'{self.system_name}\\' initialized.\")\\n            self._initialized = True\\n        else:\\n            print(f\"HospitalLogSystem \\'{self.system_name}\\' already initialized.\")\\n\\n    def log_event(self, department, event_description, severity=\"INFO\"):\\n        if not isinstance(department, str) or not isinstance(event_description, str) or not isinstance(severity, str):\\n            print(\"Invalid log parameters.\")\\n            return\\n        entry = f\"[{self.system_name}][{department}][{severity}] {event_description}\"\\n        self.log_entries.append(entry)\\n        print(f\"Logged: {entry}\")\\n\\n    def get_all_logs(self):\\n        return list(self.log_entries)\\n\\n    def clear_logs(self):\\n        self.log_entries.clear()\\n        print(f\"Logs for \\'{self.system_name}\\' cleared.\")\\n\\n\\n# Real-world usage simulation: Healthcare - Centralized Hospital Logging\\n# All departments in a hospital should log to a single, consistent logging system.\\n\\nprint(\"--- Simulation: Hospital Operations Logging ---\")\\n\\ndef er_department_activity():\\n    # The ER department needs to log events.\\n    log_system_er = HospitalLogSystem(\"St. Jude Central Log\")\\n    log_system_er.log_event(\"ER\", \"Patient admitted with severe trauma.\", \"CRITICAL\")\\n    log_system_er.log_event(\"ER\", \"Emergency surgery initiated for Patient 123.\", \"URGENT\")\\n\\ndef pharmacy_department_activity():\\n    # The Pharmacy department needs to log events.\\n    log_system_pharmacy = HospitalLogSystem(\"St. Jude Central Log\")\\n    log_system_pharmacy.log_event(\"Pharmacy\", \"Medication \\'Morphine\\' dispensed to ER.\", \"INFO\")\\n    log_system_pharmacy.log_event(\"Pharmacy\", \"Inventory update for controlled substances.\", \"AUDIT\")\\n\\ndef lab_department_activity():\\n    # The Lab department needs to log events.\\n    log_system_lab = HospitalLogSystem(\"St. Jude Central Log\")\\n    log_system_lab.log_event(\"Lab\", \"Blood test results for Patient 456 available.\", \"INFO\")\\n\\n# Simulate departments logging events\\ner_department_activity()\\npharmacy_department_activity()\\nlab_department_activity()\\n\\nprint(\"\\\\n--- Retrieving all logs from a central monitoring station ---\")\\n# A central monitoring station retrieves the logs.\\ncentral_monitor = HospitalLogSystem(\"St. Jude Central Log\")\\nprint(f\"Is central_monitor the same object as the one used by ER? {central_monitor is HospitalLogSystem(\\'St. Jude Central Log\\')}\")\\n\\nall_hospital_logs = central_monitor.get_all_logs()\\nfor log in all_hospital_logs:\\n    print(log)\\n\\nprint(\"\\\\n--- Attempting to create another \\'MainHospitalLog\\' instance ---\")\\nanother_instance = HospitalLogSystem(\"AnotherNameForLog\")\\nprint(f\"Are \\'central_monitor\\' and \\'another_instance\\' the same object? {central_monitor is another_instance}\")\\n\\nprint(\"\\\\n--- Logs from \\'another_instance\\' (should be identical) ---\")\\nfor log in another_instance.get_all_logs():\\n    print(log)\\n\\ncentral_monitor.clear_logs()\\nprint(\"\\\\n--- Verifying logs after clearing from one instance (should be empty everywhere) ---\")\\nprint(another_instance.get_all_logs())\\n']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "json_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8468cde5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
