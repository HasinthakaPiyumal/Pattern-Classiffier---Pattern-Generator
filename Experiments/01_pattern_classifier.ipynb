{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "91189e73",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "57a721af",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load model directly\n",
    "from transformers import AutoTokenizer, AutoModel\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"microsoft/codebert-base\")\n",
    "model = AutoModel.from_pretrained(\"microsoft/codebert-base\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "ba2f8647",
   "metadata": {},
   "outputs": [],
   "source": [
    "code = \"\"\"\n",
    "class AgentMemory:\n",
    "    def __init__(self):\n",
    "        self.working_memory = {\"current_task\": None, \"intermediate_steps\": []}\n",
    "        self.episodic_memory = []\n",
    "\n",
    "    def add_step(self, thought: str, action: str, action_input: dict, observation: str):\n",
    "        step = {\n",
    "            \"thought\": thought,\n",
    "            \"action\": action,\n",
    "            \"action_input\": action_input,\n",
    "            \"observation\": observation\n",
    "        }\n",
    "        self.working_memory[\"intermediate_steps\"].append(step)\n",
    "        self.episodic_memory.append(step)\n",
    "        print(f\"ðŸ§  Memory Updated: Added step for action '{action}'.\")\n",
    "\n",
    "    def get_context(self) -> str:\n",
    "        return json.dumps(self.working_memory, indent=2)\n",
    "\n",
    "    def clear_working_memory(self):\n",
    "        self.working_memory = {\"current_task\": None, \"intermediate_steps\": []}\n",
    "\n",
    "\n",
    "class ToolRegistry:\n",
    "    def __init__(self):\n",
    "        self.tools = {\n",
    "            \"get_current_time\": self.get_current_time,\n",
    "            \"calculator\": self.calculator,\n",
    "        }\n",
    "        print(f\"ðŸ”§ Tools Registered: {list(self.tools.keys())}\")\n",
    "\n",
    "    def get_tool_names(self) -> list[str]:\n",
    "        return list(self.tools.keys())\n",
    "\n",
    "    def use_tool(self, tool_name: str, tool_input: dict) -> str:\n",
    "        if tool_name in self.tools:\n",
    "            try:\n",
    "                result = self.tools[tool_name](**tool_input)\n",
    "                return f\"Tool '{tool_name}' returned: {result}\"\n",
    "            except Exception as e:\n",
    "                return f\"Error using tool '{tool_name}': {e}\"\n",
    "        else:\n",
    "            return f\"Error: Tool '{tool_name}' not found.\"\n",
    "\n",
    "    def get_current_time(self, timezone: str) -> str:\n",
    "        return datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\")\n",
    "\n",
    "    def calculator(self, expression: str) -> str:\n",
    "        return str(eval(expression, {\"__builtins__\": {}}, {}))\n",
    "\n",
    "\n",
    "class HolisticAgent:\n",
    "    def __init__(self, llm_client, memory, tool_registry):\n",
    "        self.llm = llm_client\n",
    "        self.memory = memory\n",
    "        self.tools = tool_registry\n",
    "        self.max_steps = 5\n",
    "\n",
    "    def run(self, user_query: str):\n",
    "        self.memory.clear_working_memory()\n",
    "        self.memory.working_memory[\"current_task\"] = user_query\n",
    "\n",
    "        for i in range(self.max_steps):\n",
    "            print(f\"\\n--- STEP {i+1} ---\")\n",
    "            prompt = self._build_prompt(user_query)\n",
    "\n",
    "            response_str = self.llm.query(prompt)\n",
    "            try:\n",
    "                response_json = json.loads(response_str)\n",
    "            except json.JSONDecodeError:\n",
    "                print(\"Error: LLM returned invalid JSON. Stopping.\")\n",
    "                break\n",
    "\n",
    "            thought = response_json.get(\"thought\", \"\")\n",
    "            action = response_json.get(\"action\", \"Final Answer\")\n",
    "            action_input = response_json.get(\"action_input\", \"\")\n",
    "\n",
    "            if action == \"Final Answer\":\n",
    "                print(f\"\\nâœ… Final Answer: {action_input}\")\n",
    "                break\n",
    "            \n",
    "            print(f\"ðŸ¤– Action: Using tool '{action}' with input '{action_input}'\")\n",
    "            observation = self.tools.use_tool(action, action_input)\n",
    "            print(f\"ðŸ‘€ Observation: {observation}\")\n",
    "            \n",
    "            self.memory.add_step(thought, action, action_input, observation)\n",
    "        else:\n",
    "            print(\"\\nâš ï¸ Agent stopped: Reached maximum steps.\")\n",
    "            \n",
    "    def _build_prompt(self, query: str) -> str:\n",
    "        return f\\\"\"\"\n",
    "        You are an intelligent agent. Your goal is to solve the user's request by reasoning and using the available tools.\n",
    "        Follow the Thought-Action-Observation loop (ReAct pattern).\n",
    "\n",
    "        Available Tools: {self.tools.get_tool_names()}\n",
    "\n",
    "        User Query: {query}\n",
    "        \n",
    "        Previous Steps (Memory):\n",
    "        {self.memory.get_context()}\n",
    "\n",
    "        Your response MUST be a JSON object with 'thought', 'action', and 'action_input'.\n",
    "        'action' should be one of the available tools or 'Final Answer'.\n",
    "        \\\"\"\"\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    llm_client = MockLLMClient()\n",
    "    agent_memory = AgentMemory()\n",
    "    tool_registry = ToolRegistry()\n",
    "    \n",
    "    agent = HolisticAgent(\n",
    "        llm_client=llm_client,\n",
    "        memory=agent_memory,\n",
    "        tool_registry=tool_registry\n",
    "    )\n",
    "\n",
    "    agent.run(\"What is the of Sri Lanka, what is the current time in Colombo, hi and what is 25 * 8?\")\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "53ec6065",
   "metadata": {},
   "outputs": [],
   "source": [
    "chunk_size = 128\n",
    "stride = 68"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "90800070",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_tokens = tokenizer.encode(code, add_special_tokens=False)\n",
    "total_length = len(all_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15a4868d",
   "metadata": {},
   "outputs": [],
   "source": [
    "if total_length <= chunk_size:\n",
    "    inputs = tokenizer(code,return_tensors='pt')\n",
    "else:\n",
    "    chunks = []\n",
    "    for i in range(0,total_length,stride):\n",
    "        chunk = all_tokens[i:i+chunk_size]\n",
    "        chunks.append(chunk)\n",
    "    input_ids = [tokenizer.build_inputs_with_special_tokens(chunk) for chunk in chunks]\n",
    "    max_len = max(len(ids) for ids in input_ids)\n",
    "    attention_masks = []\n",
    "    padded_input_ids = []\n",
    "    for chunk in input_ids:\n",
    "        padding_length = max_len - len(chunk)\n",
    "        padded_input_ids.append(chunk+[tokenizer.pad_token_id]*padding_length)\n",
    "        attention_masks.append([1]*len(chunk)+[0]*padding_length)\n",
    "    inputs = {'input_ids': torch.tensor(padded_input_ids), 'attention_mask': torch.tensor(attention_masks)}\n",
    "\n",
    "\n",
    "with torch.no_grad():\n",
    "    outputs = model(**inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "id": "2a9b99f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "code_embedding1 = torch.mean(outputs.pooler_output,0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd20a0ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "expanded_attention_mask = inputs['attention_mask'].unsqueeze(-1).expand(outputs.last_hidden_state.shape)\n",
    "masked_embeddings = expanded_attention_mask * outputs.last_hidden_state\n",
    "code_embedding2 = masked_embeddings.sum(1)/ expanded_attention_mask.sum(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e8d27b0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
